{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c0f0adfa-d2b1-4b1b-80bc-fe87e51ede18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/datasets/Cbl_sumry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9a810371-2271-4418-8ff9-f5e6e3bc8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_cobol = Tokenizer(filters='')\n",
    "tokenizer_cobol.fit_on_texts(df['cobol_code'])\n",
    "tokenizer_summary = Tokenizer(filters='')\n",
    "tokenizer_summary.fit_on_texts(df['summary'])\n",
    "\n",
    "# Define the vocabulary sizes\n",
    "vocab_size_cobol = len(tokenizer_cobol.word_index) + 1\n",
    "vocab_size_summary = len(tokenizer_summary.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "384ae868-b97c-495f-960a-9e973f201d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer_cobol.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7fd92beb-61b5-4abc-9d00-9363f941761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer_summary.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c073084-6973-4342-8104-56f7b8e8a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input-output pairs\n",
    "X = tokenizer_cobol.texts_to_sequences(df['cobol_code'])\n",
    "Y = tokenizer_summary.texts_to_sequences(df['summary'])\n",
    "# Pad sequences\n",
    "max_len_cobol = max([len(seq) for seq in X])\n",
    "max_len_summary = max([len(seq) for seq in Y])\n",
    "\n",
    "X = pad_sequences(X, maxlen=max_len_cobol, padding='post')\n",
    "Y = pad_sequences(Y, maxlen=max_len_summary, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92008beb-2312-4135-a738-91f2683f3b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ea8de850-834c-4091-aca5-ab14f197fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the target sequences for training\n",
    "Y_input = Y[:, :-1]\n",
    "Y_output = Y[:, 1:]\n",
    "\n",
    "# Define the Seq2Seq model\n",
    "latent_dim = 512\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len_cobol,))\n",
    "encoder_embedding = Embedding(vocab_size_cobol, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_len_summary-1,))\n",
    "decoder_embedding = Embedding(vocab_size_summary, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size_summary, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dccaff73-68bb-4407-8941-01d777ec0cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 986ms/step - accuracy: 0.0837 - loss: 5.1506 - val_accuracy: 0.5556 - val_loss: 5.1335\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.7043 - loss: 5.0914 - val_accuracy: 0.5556 - val_loss: 5.0535\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.7046 - loss: 4.9118 - val_accuracy: 0.0313 - val_loss: 5.0209\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step - accuracy: 0.2097 - loss: 4.6802 - val_accuracy: 0.5556 - val_loss: 5.4768\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.7080 - loss: 4.5576 - val_accuracy: 0.0256 - val_loss: 5.2646\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.2163 - loss: 4.2314 - val_accuracy: 0.5584 - val_loss: 5.4687\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 486ms/step - accuracy: 0.5835 - loss: 4.0501 - val_accuracy: 0.5299 - val_loss: 5.7865\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 499ms/step - accuracy: 0.5334 - loss: 3.9794 - val_accuracy: 0.2934 - val_loss: 5.4098\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 478ms/step - accuracy: 0.5066 - loss: 3.8907 - val_accuracy: 0.5869 - val_loss: 5.3282\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.7225 - loss: 3.5202 - val_accuracy: 0.5783 - val_loss: 5.3939\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 500ms/step - accuracy: 0.7223 - loss: 3.3461 - val_accuracy: 0.5413 - val_loss: 5.5585\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 530ms/step - accuracy: 0.6092 - loss: 3.2528 - val_accuracy: 0.5869 - val_loss: 5.2751\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.5559 - loss: 3.4116 - val_accuracy: 0.5869 - val_loss: 5.3689\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 0.5457 - loss: 3.2425 - val_accuracy: 0.5755 - val_loss: 5.6602\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 460ms/step - accuracy: 0.4030 - loss: 3.0942 - val_accuracy: 0.5613 - val_loss: 5.7041\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 468ms/step - accuracy: 0.4613 - loss: 2.9017 - val_accuracy: 0.5783 - val_loss: 5.4312\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - accuracy: 0.6982 - loss: 2.8777 - val_accuracy: 0.5869 - val_loss: 5.7902\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 491ms/step - accuracy: 0.5106 - loss: 2.7147 - val_accuracy: 0.5613 - val_loss: 5.6928\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 482ms/step - accuracy: 0.5825 - loss: 2.6988 - val_accuracy: 0.0969 - val_loss: 5.6306\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 477ms/step - accuracy: 0.3166 - loss: 2.6012 - val_accuracy: 0.5670 - val_loss: 5.8332\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 474ms/step - accuracy: 0.6336 - loss: 2.4511 - val_accuracy: 0.5613 - val_loss: 6.0187\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.5440 - loss: 2.6035 - val_accuracy: 0.4103 - val_loss: 5.7010\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 505ms/step - accuracy: 0.6113 - loss: 2.2036 - val_accuracy: 0.2934 - val_loss: 6.2480\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 506ms/step - accuracy: 0.3132 - loss: 2.2441 - val_accuracy: 0.2877 - val_loss: 5.9201\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 493ms/step - accuracy: 0.3990 - loss: 2.0498 - val_accuracy: 0.5328 - val_loss: 6.0961\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 483ms/step - accuracy: 0.4144 - loss: 2.0623 - val_accuracy: 0.2564 - val_loss: 6.3291\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 489ms/step - accuracy: 0.4270 - loss: 1.9065 - val_accuracy: 0.0855 - val_loss: 6.1150\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 504ms/step - accuracy: 0.2497 - loss: 1.7430 - val_accuracy: 0.1567 - val_loss: 6.7650\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 464ms/step - accuracy: 0.3212 - loss: 2.0628 - val_accuracy: 0.4786 - val_loss: 6.2031\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 459ms/step - accuracy: 0.3381 - loss: 1.8778 - val_accuracy: 0.5356 - val_loss: 6.3848\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - accuracy: 0.4190 - loss: 1.6208 - val_accuracy: 0.3305 - val_loss: 6.3381\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 530ms/step - accuracy: 0.4221 - loss: 1.5266 - val_accuracy: 0.5214 - val_loss: 6.5582\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 489ms/step - accuracy: 0.4665 - loss: 1.4498 - val_accuracy: 0.1111 - val_loss: 6.6673\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 510ms/step - accuracy: 0.3077 - loss: 1.7460 - val_accuracy: 0.4929 - val_loss: 6.2115\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 472ms/step - accuracy: 0.4612 - loss: 1.4909 - val_accuracy: 0.1254 - val_loss: 6.5273\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 460ms/step - accuracy: 0.4180 - loss: 1.3224 - val_accuracy: 0.3561 - val_loss: 6.9392\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 493ms/step - accuracy: 0.4359 - loss: 1.3440 - val_accuracy: 0.5299 - val_loss: 6.4850\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 545ms/step - accuracy: 0.4925 - loss: 1.4098 - val_accuracy: 0.2792 - val_loss: 6.6768\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 482ms/step - accuracy: 0.4205 - loss: 1.2136 - val_accuracy: 0.4103 - val_loss: 6.7789\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 490ms/step - accuracy: 0.4778 - loss: 1.1679 - val_accuracy: 0.4501 - val_loss: 6.8834\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.5200 - loss: 1.0779 - val_accuracy: 0.1054 - val_loss: 7.0583\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 481ms/step - accuracy: 0.3600 - loss: 1.2445 - val_accuracy: 0.4843 - val_loss: 6.9184\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 478ms/step - accuracy: 0.4390 - loss: 1.0209 - val_accuracy: 0.3789 - val_loss: 7.1326\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 521ms/step - accuracy: 0.4799 - loss: 1.0080 - val_accuracy: 0.4644 - val_loss: 7.0188\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - accuracy: 0.4786 - loss: 1.0251 - val_accuracy: 0.1282 - val_loss: 6.8541\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 518ms/step - accuracy: 0.4273 - loss: 0.9244 - val_accuracy: 0.1453 - val_loss: 7.1480\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.4568 - loss: 0.7733 - val_accuracy: 0.2650 - val_loss: 7.1685\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 474ms/step - accuracy: 0.4460 - loss: 0.9988 - val_accuracy: 0.1652 - val_loss: 7.2654\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 490ms/step - accuracy: 0.4611 - loss: 1.1823 - val_accuracy: 0.2251 - val_loss: 7.0377\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 478ms/step - accuracy: 0.4927 - loss: 0.8301 - val_accuracy: 0.3419 - val_loss: 7.2347\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 493ms/step - accuracy: 0.4711 - loss: 0.7305 - val_accuracy: 0.3276 - val_loss: 7.2682\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - accuracy: 0.4617 - loss: 0.7956 - val_accuracy: 0.4473 - val_loss: 7.3447\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 471ms/step - accuracy: 0.5579 - loss: 0.6087 - val_accuracy: 0.2536 - val_loss: 7.3736\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 494ms/step - accuracy: 0.4806 - loss: 0.6443 - val_accuracy: 0.2251 - val_loss: 7.4480\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 502ms/step - accuracy: 0.4360 - loss: 0.8155 - val_accuracy: 0.3390 - val_loss: 7.4425\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 459ms/step - accuracy: 0.4822 - loss: 0.6261 - val_accuracy: 0.4359 - val_loss: 7.6379\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.5111 - loss: 0.7358 - val_accuracy: 0.1026 - val_loss: 7.5931\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 461ms/step - accuracy: 0.4104 - loss: 0.7767 - val_accuracy: 0.3276 - val_loss: 7.5150\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 460ms/step - accuracy: 0.5048 - loss: 0.6962 - val_accuracy: 0.1738 - val_loss: 7.3376\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 489ms/step - accuracy: 0.5717 - loss: 0.5614 - val_accuracy: 0.2906 - val_loss: 7.4560\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 481ms/step - accuracy: 0.5987 - loss: 0.5562 - val_accuracy: 0.2023 - val_loss: 7.4905\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 463ms/step - accuracy: 0.6174 - loss: 0.5151 - val_accuracy: 0.4644 - val_loss: 7.6944\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 469ms/step - accuracy: 0.6304 - loss: 0.5361 - val_accuracy: 0.1994 - val_loss: 7.6936\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.5678 - loss: 0.4388 - val_accuracy: 0.4615 - val_loss: 7.7130\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.5801 - loss: 0.4516 - val_accuracy: 0.2222 - val_loss: 7.9873\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 468ms/step - accuracy: 0.5379 - loss: 0.5188 - val_accuracy: 0.5071 - val_loss: 7.7089\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 477ms/step - accuracy: 0.6239 - loss: 0.4841 - val_accuracy: 0.2194 - val_loss: 7.9743\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.5196 - loss: 0.5204 - val_accuracy: 0.3134 - val_loss: 7.8484\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 486ms/step - accuracy: 0.6951 - loss: 0.7357 - val_accuracy: 0.4843 - val_loss: 7.5321\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 464ms/step - accuracy: 0.7254 - loss: 0.4218 - val_accuracy: 0.4387 - val_loss: 7.5916\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 488ms/step - accuracy: 0.7560 - loss: 0.3796 - val_accuracy: 0.4444 - val_loss: 7.7639\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 501ms/step - accuracy: 0.7301 - loss: 0.3338 - val_accuracy: 0.5584 - val_loss: 7.8213\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 471ms/step - accuracy: 0.8212 - loss: 0.3673 - val_accuracy: 0.3761 - val_loss: 7.7170\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 482ms/step - accuracy: 0.6939 - loss: 0.4919 - val_accuracy: 0.4900 - val_loss: 7.5080\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 472ms/step - accuracy: 0.7148 - loss: 0.5066 - val_accuracy: 0.3504 - val_loss: 7.5099\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - accuracy: 0.6899 - loss: 0.3457 - val_accuracy: 0.2821 - val_loss: 7.4948\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 501ms/step - accuracy: 0.5995 - loss: 0.3648 - val_accuracy: 0.4302 - val_loss: 7.9652\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 468ms/step - accuracy: 0.6903 - loss: 0.2962 - val_accuracy: 0.4017 - val_loss: 7.8921\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 569ms/step - accuracy: 0.7243 - loss: 0.3215 - val_accuracy: 0.3048 - val_loss: 7.9737\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 635ms/step - accuracy: 0.6479 - loss: 0.3219 - val_accuracy: 0.3561 - val_loss: 7.9543\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 516ms/step - accuracy: 0.7764 - loss: 0.2835 - val_accuracy: 0.3903 - val_loss: 8.0823\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 602ms/step - accuracy: 0.6718 - loss: 0.2962 - val_accuracy: 0.4501 - val_loss: 7.9163\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 589ms/step - accuracy: 0.7123 - loss: 0.2941 - val_accuracy: 0.4046 - val_loss: 8.2541\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.6880 - loss: 0.2932 - val_accuracy: 0.3989 - val_loss: 7.9298\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 491ms/step - accuracy: 0.6918 - loss: 0.2517 - val_accuracy: 0.4274 - val_loss: 8.0768\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 513ms/step - accuracy: 0.7947 - loss: 0.2671 - val_accuracy: 0.1652 - val_loss: 8.4681\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 491ms/step - accuracy: 0.6730 - loss: 0.2871 - val_accuracy: 0.5242 - val_loss: 7.9546\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 458ms/step - accuracy: 0.6978 - loss: 0.2704 - val_accuracy: 0.3618 - val_loss: 7.8585\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 503ms/step - accuracy: 0.7271 - loss: 0.2794 - val_accuracy: 0.3732 - val_loss: 7.9771\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 621ms/step - accuracy: 0.7378 - loss: 0.2239 - val_accuracy: 0.4330 - val_loss: 8.1954\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 993ms/step - accuracy: 0.7581 - loss: 0.2004 - val_accuracy: 0.3875 - val_loss: 8.1647\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 536ms/step - accuracy: 0.7121 - loss: 0.2093 - val_accuracy: 0.4672 - val_loss: 8.2475\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 476ms/step - accuracy: 0.8005 - loss: 0.1889 - val_accuracy: 0.3704 - val_loss: 8.2266\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 531ms/step - accuracy: 0.7287 - loss: 0.2098 - val_accuracy: 0.4160 - val_loss: 8.4539\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 491ms/step - accuracy: 0.7334 - loss: 0.1988 - val_accuracy: 0.3561 - val_loss: 8.3771\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 505ms/step - accuracy: 0.7183 - loss: 0.1962 - val_accuracy: 0.4046 - val_loss: 8.3687\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 479ms/step - accuracy: 0.7485 - loss: 0.1881 - val_accuracy: 0.3732 - val_loss: 8.4603\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 474ms/step - accuracy: 0.7783 - loss: 0.1958 - val_accuracy: 0.3447 - val_loss: 8.4306\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 473ms/step - accuracy: 0.7426 - loss: 0.1324 - val_accuracy: 0.3704 - val_loss: 8.5287\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544ms/step - accuracy: 0.7630 - loss: 0.1917 - val_accuracy: 0.1709 - val_loss: 8.4788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a5eb64e250>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([X, Y[:,:-1]], Y.reshape(Y.shape[0], Y.shape[1], 1)[:,1:],batch_size=10, epochs=100, validation_split=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ee7f066-6061-42c5-a641-24e4acd5e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('seq2seq_model_c2s.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c711bf44-421b-48b3-b478-638adb28ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662ms/step\n",
      "Sequence Accuracy: 46.51%\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming your test data is loaded and preprocessed similarly to the training data\n",
    "df_test = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/datasets/Cbl_sumry.csv\")\n",
    "X_test = tokenizer_cobol.texts_to_sequences(df_test['cobol_code'])\n",
    "Y_test = tokenizer_summary.texts_to_sequences(df_test['summary'])\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len_cobol, padding='post')\n",
    "Y_test = pad_sequences(Y_test, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/seq2seq_model_c2s.keras\")\n",
    "\n",
    "# Function to calculate sequence accuracy\n",
    "def sequence_accuracy(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for true_seq, pred_seq in zip(y_true, y_pred):\n",
    "        true_seq = true_seq[true_seq != 0]  # Remove padding\n",
    "        pred_seq = pred_seq[:len(true_seq)]  # Truncate to the length of the true sequence\n",
    "        if np.array_equal(true_seq, pred_seq):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n",
    "# Generate predictions\n",
    "Y_pred = model.predict([X_test, Y_test[:, :-1]])\n",
    "\n",
    "# Convert predictions to sequences of token ids\n",
    "Y_pred_sequences = np.argmax(Y_pred, axis=-1)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = sequence_accuracy(Y_test[:, 1:], Y_pred_sequences)\n",
    "print(f'Sequence Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f8257ae5-0cfb-4c88-a30d-f5cca7be0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/seq2seq_model_c2s.keras\")\n",
    "\n",
    "def preprocess_input(cobol_code, tokenizer_cobol, max_len_cobol):\n",
    "    # Tokenize the input COBOL code\n",
    "    sequence = tokenizer_cobol.texts_to_sequences([cobol_code])\n",
    "    # Pad the sequence\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len_cobol, padding='post')\n",
    "    return padded_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "79da8e92-57c8-44e1-b84d-327d6b895118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_summary(cobol_code, model, tokenizer_cobol, tokenizer_summary, max_len_cobol, max_len_summary):\n",
    "    # Preprocess the input COBOL code\n",
    "    input_seq = preprocess_input(cobol_code, tokenizer_cobol, max_len_cobol)\n",
    "    \n",
    "    # Initialize the decoder input\n",
    "    decoder_input = np.zeros((1, max_len_summary - 1))\n",
    "    \n",
    "    # Predict the summary\n",
    "    for i in range(max_len_summary - 1):\n",
    "        output_tokens = model.predict([input_seq, decoder_input])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, i, :])\n",
    "        decoder_input[0, i] = sampled_token_index\n",
    "        \n",
    "        # Stop if a zero token (padding) is predicted, indicating no more meaningful tokens\n",
    "        if sampled_token_index == 0:\n",
    "            break\n",
    "    \n",
    "    # Convert token indices back to words\n",
    "    predicted_summary = []\n",
    "    for token in decoder_input[0]:\n",
    "        if token == 0:\n",
    "            continue\n",
    "        word = tokenizer_summary.index_word.get(token, '')\n",
    "        predicted_summary.append(word)\n",
    "    \n",
    "    return ' '.join(predicted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ee1495e2-d8ad-4bd7-be39-113019666b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Summary: is a 01 variable stores numeric\n"
     ]
    }
   ],
   "source": [
    "# Define your COBOL code to be summarized\n",
    "cobol_code_example = \"PRODUCT-ID\"\n",
    "\n",
    "# Predict the summary\n",
    "summary = predict_summary(cobol_code_example, model, tokenizer_cobol, tokenizer_summary, max_len_cobol, max_len_summary)\n",
    "print(f'Summary: {summary}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a3cd9-1b24-46fd-ba9f-13bcbc42bde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aae4bd-5c2c-4805-9e6a-a25966fd4f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
