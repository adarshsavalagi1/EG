{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a176e9-5d68-4d09-8930-e7c21f753a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777f68c1-aa49-4742-9dc4-171a80f95d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/cob_py.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e07f15c-dd58-4c02-a3e9-c6d5db123e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da4dff5-1fef-4729-82c2-232310ee1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobol_tokenizer = Tokenizer(filters='', char_level=True)\n",
    "cobol_tokenizer.fit_on_texts(df['cobol_code'])\n",
    "cobol_seq = cobol_tokenizer.texts_to_sequences(df['cobol_code'])\n",
    "cobol_seq_padded = pad_sequences(cobol_seq, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef853bfc-0675-428d-9cc7-0df1893fffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cobol_seq_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4e8c3c-bc7f-44cb-bb54-4f2a92ec463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "df['python_code'] = df['python_code'].astype(str)\n",
    "python_tokenizer = Tokenizer(filters='', char_level=True)\n",
    "python_tokenizer.fit_on_texts(df['python_code'])\n",
    "python_seq = python_tokenizer.texts_to_sequences(df['python_code'])\n",
    "python_seq_padded = pad_sequences(python_seq, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654e05e9-00a2-470a-91eb-bca6771195df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python_seq_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60cfc9d7-8f96-495f-aa1c-dc752646c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "cobol_vocab_size = len(cobol_tokenizer.word_index) + 1\n",
    "python_vocab_size = len(python_tokenizer.word_index) + 1\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3a9b64-3e9a-4689-96b6-2bc0ed6c595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(cobol_vocab_size, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "_, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(python_vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm1(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_outputs, _, _ = decoder_lstm2(decoder_outputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(python_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb55802d-5f28-493d-8cbd-383e029bd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0544af6-cc8a-4a01-9549-7a05d2203a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "416d92d4-6fab-4a5e-a22f-6bbd85d80169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - loss: 4.0578 - val_loss: 3.7041\n",
      "Epoch 2/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - loss: 3.6040 - val_loss: 3.5955\n",
      "Epoch 3/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6s/step - loss: 3.4414 - val_loss: 3.5467\n",
      "Epoch 4/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - loss: 3.3799 - val_loss: 3.5417\n",
      "Epoch 5/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 3.3584 - val_loss: 3.5413\n",
      "Epoch 6/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5s/step - loss: 3.3626 - val_loss: 3.5118\n",
      "Epoch 7/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7s/step - loss: 3.3404 - val_loss: 3.4926\n",
      "Epoch 8/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 3.3313 - val_loss: 3.4818\n",
      "Epoch 9/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 3.2776 - val_loss: 3.4327\n",
      "Epoch 10/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - loss: 3.2346 - val_loss: 3.3356\n",
      "Epoch 11/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - loss: 3.1292 - val_loss: 3.1998\n",
      "Epoch 12/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step - loss: 2.9895 - val_loss: 3.0342\n",
      "Epoch 13/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step - loss: 2.8310 - val_loss: 2.8825\n",
      "Epoch 14/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8s/step - loss: 2.6686 - val_loss: 2.7288\n",
      "Epoch 15/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7s/step - loss: 2.4560 - val_loss: 2.5567\n",
      "Epoch 16/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - loss: 2.2777 - val_loss: 2.3687\n",
      "Epoch 17/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 2.0545 - val_loss: 2.1793\n",
      "Epoch 18/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 1.8244 - val_loss: 1.9932\n",
      "Epoch 19/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - loss: 1.6230 - val_loss: 1.8137\n",
      "Epoch 20/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 1.4365 - val_loss: 1.6517\n",
      "Epoch 21/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6s/step - loss: 1.2525 - val_loss: 1.4964\n",
      "Epoch 22/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - loss: 1.1416 - val_loss: 1.3528\n",
      "Epoch 23/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - loss: 0.9403 - val_loss: 1.2370\n",
      "Epoch 24/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.8376 - val_loss: 1.1144\n",
      "Epoch 25/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - loss: 0.7577 - val_loss: 1.0105\n",
      "Epoch 26/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - loss: 0.6756 - val_loss: 0.9148\n",
      "Epoch 27/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.5838 - val_loss: 0.8308\n",
      "Epoch 28/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 0.4911 - val_loss: 0.7568\n",
      "Epoch 29/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5s/step - loss: 0.4448 - val_loss: 0.6957\n",
      "Epoch 30/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - loss: 0.4044 - val_loss: 0.6440\n",
      "Epoch 31/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 0.3638 - val_loss: 0.5989\n",
      "Epoch 32/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - loss: 0.3232 - val_loss: 0.5561\n",
      "Epoch 33/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 0.2972 - val_loss: 0.5212\n",
      "Epoch 34/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - loss: 0.2494 - val_loss: 0.4886\n",
      "Epoch 35/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - loss: 0.2318 - val_loss: 0.4542\n",
      "Epoch 36/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - loss: 0.2030 - val_loss: 0.4290\n",
      "Epoch 37/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - loss: 0.1913 - val_loss: 0.4092\n",
      "Epoch 38/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - loss: 0.1692 - val_loss: 0.3902\n",
      "Epoch 39/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.1515 - val_loss: 0.3712\n",
      "Epoch 40/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step - loss: 0.1350 - val_loss: 0.3505\n",
      "Epoch 41/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - loss: 0.1290 - val_loss: 0.3323\n",
      "Epoch 42/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step - loss: 0.1218 - val_loss: 0.3164\n",
      "Epoch 43/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - loss: 0.1067 - val_loss: 0.3048\n",
      "Epoch 44/44\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - loss: 0.0994 - val_loss: 0.2914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27912ab1010>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([cobol_seq_padded, python_seq_padded], np.expand_dims(python_seq_padded, -1), batch_size=10, epochs=44, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce10b106-5814-4fac-8ccb-12f45f42cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('cob_to_py.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbd1ad-776a-40bf-82bd-740e648c5ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c371076-e78d-42bf-aa9b-3b662bdb2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jabasingh Daniel\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 15 variables whereas the saved optimizer has 28 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849ms/step\n",
      "Accuracy: 0.43292546026044004\n",
      "Confusion Matrix:\n",
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0 1131    0 ...    0    0    0]\n",
      " [   0    0  488 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/cob_py.csv\")\n",
    "\n",
    "# Tokenization\n",
    "# Assume you have already tokenized and padded the sequences as shown in your previous code\n",
    "\n",
    "# Load the trained seq2seq model\n",
    "model = load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/cob_to_py.keras\")\n",
    "\n",
    "# Evaluate the model on the dataset\n",
    "predictions = model.predict([cobol_seq_padded, python_seq_padded])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Flatten the predictions and ground truth sequences for computing accuracy\n",
    "predictions_flat = predictions.flatten()\n",
    "python_seq_padded_flat = python_seq_padded.flatten()\n",
    "\n",
    "# Calculate accuracy and confusion matrix\n",
    "accuracy = accuracy_score(python_seq_padded_flat, predictions_flat)\n",
    "conf_matrix = confusion_matrix(python_seq_padded_flat, predictions_flat)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03700f7f-e5a5-4cd7-962b-4296c48d0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/cob_to_py.keras\")\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=80\n",
    "# Tokenize and pad the COBOL code snippet\n",
    "cobol_code = \"IDENTIFICATION DIVISION. PROGRAM-ID. HelloWorld. PROCEDURE DIVISION. DISPLAY 'Hello, World!'. STOP RUN.\"\n",
    "cobol_seq = cobol_tokenizer.texts_to_sequences([cobol_code])\n",
    "cobol_seq_padded = pad_sequences(cobol_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "cobol_tokenizer = Tokenizer(filters='', char_level=True)\n",
    "cobol_tokenizer.fit_on_texts(df['cobol_code'])\n",
    "\n",
    "python_tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "python_tokenizer.fit_on_texts(df['python_code'].astype(str))\n",
    "python_tokenizer.word_index['\\n'] = len(python_tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "# Generate the Python code snippet\n",
    "zero_input = np.zeros((1, 1))\n",
    "\n",
    "predicted_sequence = []\n",
    "for _ in range(MAX_SEQUENCE_LENGTH):\n",
    "    output = model.layers[2](zero_input)\n",
    "    predicted_id = tf.argmax(output[0]).numpy()\n",
    "    if (predicted_id == python_tokenizer.word_index['\\n']).any():\n",
    "      break\n",
    "    predicted_sequence.append(predicted_id)\n",
    "    zero_input = np.array([[predicted_id]])\n",
    "\n",
    "predicted_python_code = python_tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
    "print(\"Predicted Python Code:\")\n",
    "print(predicted_python_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306fcf9-cfc5-4cc1-aaae-b2970a182b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f8892-dafd-4706-92ba-f693fc621061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/cob_to_py.keras\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/cob_py.csv\")\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 80\n",
    "\n",
    "# Tokenize and pad the COBOL code snippet\n",
    "cobol_tokenizer = Tokenizer(filters='', char_level=True)\n",
    "cobol_tokenizer.fit_on_texts(df['cobol_code'])\n",
    "cobol_code = \"IDENTIFICATION DIVISION. PROGRAM-ID. HelloWorld. PROCEDURE DIVISION. DISPLAY 'Hello, World!'. STOP RUN.\"\n",
    "cobol_seq = cobol_tokenizer.texts_to_sequences([cobol_code])\n",
    "cobol_seq_padded = pad_sequences(cobol_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# Tokenize and pad the Python code snippets\n",
    "python_tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "python_tokenizer.fit_on_texts(df['python_code'].astype(str))\n",
    "python_tokenizer.word_index['\\n'] = len(python_tokenizer.word_index) + 1\n",
    "\n",
    "# Define the model with Embedding layer\n",
    "python_vocab_size = len(python_tokenizer.word_index) + 1\n",
    "latent_dim = 256\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(python_vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
    "decoder_dense = Dense(python_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Generate the Python code snippet\n",
    "zero_input = np.zeros((1, 1))\n",
    "\n",
    "predicted_sequence = []\n",
    "for _ in range(MAX_SEQUENCE_LENGTH):\n",
    "    output = model.layers[2](zero_input)\n",
    "    predicted_id = tf.argmax(output[0]).numpy()\n",
    "    if (predicted_id == python_tokenizer.word_index['\\n']).any():\n",
    "        break\n",
    "    predicted_sequence.append(predicted_id)\n",
    "    zero_input = np.array([[predicted_id]])\n",
    "\n",
    "predicted_python_code = python_tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
    "print(\"Predicted Python Code:\")\n",
    "print(predicted_python_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c431ca-dd80-4dfc-aae4-1287327b13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date : 12-05-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1523dd98-8584-4e7c-a78b-e137a2c37f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, RepeatVector, Attention, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the CSV dataset\n",
    "data = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/cob_py.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "cobol_text = data[\"cobol_code\"].tolist()\n",
    "python_text = data[\"python_code\"].tolist()\n",
    "python_text = [str(item) for item in python_text]\n",
    "\n",
    "# Create separate tokenizers for COBOL and Python\n",
    "cobol_tokenizer = Tokenizer(num_words=5000)  # Adjust vocabulary size as needed\n",
    "cobol_tokenizer.fit_on_texts(cobol_text)\n",
    "\n",
    "python_tokenizer = Tokenizer(num_words=5000)\n",
    "python_tokenizer.fit_on_texts(python_text)\n",
    "\n",
    "# Convert text data to sequences of token indices\n",
    "cobol_sequences = cobol_tokenizer.texts_to_sequences(cobol_text)\n",
    "python_sequences = python_tokenizer.texts_to_sequences(python_text)\n",
    "\n",
    "# Pad sequences to have the same length (max_cobol_length and max_python_length)\n",
    "max_cobol_length = max(len(seq) for seq in cobol_sequences)\n",
    "max_python_length = max(len(seq) for seq in python_sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72e514b7-227f-49bf-86fd-22cbbb6e5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobol_sequences = pad_sequences(cobol_sequences, maxlen=max_cobol_length, padding=\"post\")\n",
    "python_sequences = pad_sequences(python_sequences, maxlen=max_python_length, padding=\"post\")\n",
    "\n",
    "# Separate target sequences from decoder inputs (teacher forcing)\n",
    "decoder_target_data = python_sequences[:, 1:]  # Exclude the first token (start of sequence)\n",
    "decoder_input_data = python_sequences[:, :-1]  # Exclude the last token (end of sequence)\n",
    "\n",
    "# Create embedding layers for COBOL and Python tokens\n",
    "cobol_embedding_dim = 128  # Adjust embedding dimension as needed\n",
    "python_embedding_dim = cobol_embedding_dim\n",
    "\n",
    "cobol_embedding = Embedding(cobol_tokenizer.num_words, cobol_embedding_dim, mask_zero=True)\n",
    "python_embedding = Embedding(python_tokenizer.num_words, python_embedding_dim, mask_zero=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2823b775-2f34-4808-9d2f-4753dd7df9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_cobol_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8e7dc56-04cc-4455-96e8-dcaa1ff7bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Define the encoder\n",
    "encoder_inputs = tf.keras.Input(shape=(max_cobol_length,))\n",
    "encoded = cobol_embedding(encoder_inputs)\n",
    "encoded = LSTM(1024, return_sequences=True)(encoded)  # Adjust LSTM units as needed\n",
    "encoded = LSTM(512, return_sequences=True)(encoded) \n",
    "encoded = LSTM(360, return_sequences=True)(encoded)\n",
    "encoded = LSTM(128)(encoded)  # Adjust LSTM units as needed\n",
    "\n",
    "# Define the decoder\n",
    "decoder_inputs = tf.keras.Input(shape=(max_python_length - 1,))\n",
    "decoder_embedding = python_embedding(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM with dropout for regularization\n",
    "decoder_lstm = LSTM(1024, return_sequences=True)(decoder_embedding)\n",
    "decoder_lstm = LSTM(512, return_sequences=True)(decoder_lstm)\n",
    "decoder_lstm = LSTM(360, return_sequences=True)(decoder_lstm)\n",
    "decoder_lstm = LSTM(150, return_sequences=True)(decoder_lstm)\n",
    "\n",
    "decoder_lstm = Dropout(0.2)(decoder_lstm)  # Adjust dropout rate as needed\n",
    "\n",
    "# Decoder output layer\n",
    "decoder_outputs = Dense(python_tokenizer.num_words, activation=\"softmax\")(decoder_lstm)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert target data to one-hot encoding\n",
    "decoder_target_data_one_hot = to_categorical(decoder_target_data, num_classes=python_tokenizer.num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b3b8d71f-590d-48f6-9988-1724ae20e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "# Compile the model (optimizer, loss function, metrics)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "#early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d602138a-2603-499b-ac27-98046b39e837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6s/step - accuracy: 0.0021 - loss: 8.5168 - val_accuracy: 0.0000e+00 - val_loss: 8.5108\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0290 - loss: 8.5031 - val_accuracy: 0.0153 - val_loss: 8.4193\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0170 - loss: 8.3679 - val_accuracy: 0.0153 - val_loss: 8.2644\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0189 - loss: 8.1350 - val_accuracy: 0.0153 - val_loss: 8.0479\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0189 - loss: 7.7943 - val_accuracy: 0.0153 - val_loss: 7.7851\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5s/step - accuracy: 0.0171 - loss: 7.3888 - val_accuracy: 0.0153 - val_loss: 7.5127\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.0183 - loss: 6.9641 - val_accuracy: 0.0153 - val_loss: 7.2609\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0177 - loss: 6.5462 - val_accuracy: 0.0153 - val_loss: 7.0494\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0183 - loss: 6.1836 - val_accuracy: 0.0153 - val_loss: 6.8823\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0175 - loss: 5.8636 - val_accuracy: 0.0153 - val_loss: 6.7661\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0185 - loss: 5.5837 - val_accuracy: 0.0153 - val_loss: 6.6992\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0189 - loss: 5.3887 - val_accuracy: 0.0153 - val_loss: 6.6717\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - accuracy: 0.0185 - loss: 5.2205 - val_accuracy: 0.0153 - val_loss: 6.6798\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5s/step - accuracy: 0.0175 - loss: 5.0837 - val_accuracy: 0.0153 - val_loss: 6.7117\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step - accuracy: 0.0173 - loss: 4.9636 - val_accuracy: 0.0153 - val_loss: 6.7637\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0162 - loss: 4.9354 - val_accuracy: 0.0153 - val_loss: 6.8251\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.0197 - loss: 4.8808 - val_accuracy: 0.0153 - val_loss: 6.8955\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0176 - loss: 4.8638 - val_accuracy: 0.0153 - val_loss: 6.9672\n",
      "Epoch 19/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0188 - loss: 4.8265 - val_accuracy: 0.0000e+00 - val_loss: 7.0314\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - accuracy: 0.0226 - loss: 4.8130 - val_accuracy: 0.0000e+00 - val_loss: 7.0877\n",
      "Epoch 21/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0233 - loss: 4.7793 - val_accuracy: 0.0000e+00 - val_loss: 7.1397\n",
      "Epoch 22/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0244 - loss: 4.8098 - val_accuracy: 0.0000e+00 - val_loss: 7.1815\n",
      "Epoch 23/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0240 - loss: 4.7906 - val_accuracy: 0.0000e+00 - val_loss: 7.2144\n",
      "Epoch 24/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - accuracy: 0.0248 - loss: 4.7582 - val_accuracy: 0.0000e+00 - val_loss: 7.2390\n",
      "Epoch 25/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.0235 - loss: 4.7919 - val_accuracy: 0.0000e+00 - val_loss: 7.2576\n",
      "Epoch 26/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0258 - loss: 4.7158 - val_accuracy: 0.0000e+00 - val_loss: 7.2730\n",
      "Epoch 27/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0231 - loss: 4.7595 - val_accuracy: 0.0000e+00 - val_loss: 7.2849\n",
      "Epoch 28/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0226 - loss: 4.7491 - val_accuracy: 0.0000e+00 - val_loss: 7.2995\n",
      "Epoch 29/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0250 - loss: 4.7796 - val_accuracy: 0.0000e+00 - val_loss: 7.3150\n",
      "Epoch 30/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0231 - loss: 4.7631 - val_accuracy: 0.0000e+00 - val_loss: 7.3286\n",
      "Epoch 31/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0226 - loss: 4.7278 - val_accuracy: 0.0000e+00 - val_loss: 7.3390\n",
      "Epoch 32/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0223 - loss: 4.7491 - val_accuracy: 0.0000e+00 - val_loss: 7.3477\n",
      "Epoch 33/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0201 - loss: 4.7706 - val_accuracy: 0.0000e+00 - val_loss: 7.3562\n",
      "Epoch 34/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0220 - loss: 4.7698 - val_accuracy: 0.0000e+00 - val_loss: 7.3680\n",
      "Epoch 35/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0221 - loss: 4.7424 - val_accuracy: 0.0000e+00 - val_loss: 7.3787\n",
      "Epoch 36/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0203 - loss: 4.7569 - val_accuracy: 0.0000e+00 - val_loss: 7.3917\n",
      "Epoch 37/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0243 - loss: 4.7414 - val_accuracy: 0.0000e+00 - val_loss: 7.4061\n",
      "Epoch 38/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0233 - loss: 4.7560 - val_accuracy: 0.0000e+00 - val_loss: 7.4162\n",
      "Epoch 39/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0247 - loss: 4.7192 - val_accuracy: 0.0000e+00 - val_loss: 7.4251\n",
      "Epoch 40/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0245 - loss: 4.7516 - val_accuracy: 0.0000e+00 - val_loss: 7.4319\n",
      "Epoch 41/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0225 - loss: 4.7436 - val_accuracy: 0.0000e+00 - val_loss: 7.4389\n",
      "Epoch 42/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0219 - loss: 4.7606 - val_accuracy: 0.0000e+00 - val_loss: 7.4462\n",
      "Epoch 43/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0246 - loss: 4.7426 - val_accuracy: 0.0000e+00 - val_loss: 7.4514\n",
      "Epoch 44/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0236 - loss: 4.7419 - val_accuracy: 0.0000e+00 - val_loss: 7.4531\n",
      "Epoch 45/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0230 - loss: 4.7577 - val_accuracy: 0.0000e+00 - val_loss: 7.4526\n",
      "Epoch 46/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0220 - loss: 4.7444 - val_accuracy: 0.0000e+00 - val_loss: 7.4570\n",
      "Epoch 47/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0252 - loss: 4.7724 - val_accuracy: 0.0000e+00 - val_loss: 7.4683\n",
      "Epoch 48/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0239 - loss: 4.7261 - val_accuracy: 0.0000e+00 - val_loss: 7.4773\n",
      "Epoch 49/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0228 - loss: 4.7278 - val_accuracy: 0.0000e+00 - val_loss: 7.4857\n",
      "Epoch 50/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0237 - loss: 4.7548 - val_accuracy: 0.0000e+00 - val_loss: 7.4895\n",
      "Epoch 51/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0258 - loss: 4.7502 - val_accuracy: 0.0000e+00 - val_loss: 7.4936\n",
      "Epoch 52/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0227 - loss: 4.7750 - val_accuracy: 0.0000e+00 - val_loss: 7.4971\n",
      "Epoch 53/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0220 - loss: 4.7237 - val_accuracy: 0.0000e+00 - val_loss: 7.5014\n",
      "Epoch 54/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0239 - loss: 4.7421 - val_accuracy: 0.0000e+00 - val_loss: 7.5106\n",
      "Epoch 55/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0256 - loss: 4.7371 - val_accuracy: 0.0000e+00 - val_loss: 7.5197\n",
      "Epoch 56/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0247 - loss: 4.7651 - val_accuracy: 0.0000e+00 - val_loss: 7.5275\n",
      "Epoch 57/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0238 - loss: 4.7555 - val_accuracy: 0.0000e+00 - val_loss: 7.5367\n",
      "Epoch 58/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0188 - loss: 4.7116 - val_accuracy: 0.0000e+00 - val_loss: 7.5450\n",
      "Epoch 59/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0204 - loss: 4.7264 - val_accuracy: 0.0000e+00 - val_loss: 7.5534\n",
      "Epoch 60/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0211 - loss: 4.7379 - val_accuracy: 0.0000e+00 - val_loss: 7.5575\n",
      "Epoch 61/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0200 - loss: 4.7214 - val_accuracy: 0.0000e+00 - val_loss: 7.5608\n",
      "Epoch 62/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0218 - loss: 4.7489 - val_accuracy: 0.0000e+00 - val_loss: 7.5641\n",
      "Epoch 63/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0217 - loss: 4.7287 - val_accuracy: 0.0000e+00 - val_loss: 7.5672\n",
      "Epoch 64/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0208 - loss: 4.7208 - val_accuracy: 0.0000e+00 - val_loss: 7.5731\n",
      "Epoch 65/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0219 - loss: 4.7432 - val_accuracy: 0.0000e+00 - val_loss: 7.5812\n",
      "Epoch 66/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0215 - loss: 4.7211 - val_accuracy: 0.0000e+00 - val_loss: 7.5959\n",
      "Epoch 67/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0228 - loss: 4.7218 - val_accuracy: 0.0000e+00 - val_loss: 7.6099\n",
      "Epoch 68/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0235 - loss: 4.7356 - val_accuracy: 0.0000e+00 - val_loss: 7.6216\n",
      "Epoch 69/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0233 - loss: 4.7472 - val_accuracy: 0.0000e+00 - val_loss: 7.6322\n",
      "Epoch 70/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0218 - loss: 4.6954 - val_accuracy: 0.0000e+00 - val_loss: 7.6424\n",
      "Epoch 71/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0220 - loss: 4.7205 - val_accuracy: 0.0000e+00 - val_loss: 7.6511\n",
      "Epoch 72/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0216 - loss: 4.7188 - val_accuracy: 0.0000e+00 - val_loss: 7.6612\n",
      "Epoch 73/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0235 - loss: 4.7455 - val_accuracy: 0.0000e+00 - val_loss: 7.6684\n",
      "Epoch 74/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0236 - loss: 4.7209 - val_accuracy: 0.0000e+00 - val_loss: 7.6722\n",
      "Epoch 75/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0225 - loss: 4.7024 - val_accuracy: 0.0000e+00 - val_loss: 7.6745\n",
      "Epoch 76/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0224 - loss: 4.7277 - val_accuracy: 0.0000e+00 - val_loss: 7.6742\n",
      "Epoch 77/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0258 - loss: 4.7392 - val_accuracy: 0.0000e+00 - val_loss: 7.6713\n",
      "Epoch 78/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0215 - loss: 4.7462 - val_accuracy: 0.0000e+00 - val_loss: 7.6657\n",
      "Epoch 79/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0230 - loss: 4.7375 - val_accuracy: 0.0000e+00 - val_loss: 7.6650\n",
      "Epoch 80/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0239 - loss: 4.7508 - val_accuracy: 0.0000e+00 - val_loss: 7.6684\n",
      "Epoch 81/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0213 - loss: 4.7562 - val_accuracy: 0.0000e+00 - val_loss: 7.6752\n",
      "Epoch 82/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0237 - loss: 4.7177 - val_accuracy: 0.0000e+00 - val_loss: 7.6819\n",
      "Epoch 83/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0224 - loss: 4.7457 - val_accuracy: 0.0000e+00 - val_loss: 7.6817\n",
      "Epoch 84/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0240 - loss: 4.7094 - val_accuracy: 0.0000e+00 - val_loss: 7.6821\n",
      "Epoch 85/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0237 - loss: 4.7240 - val_accuracy: 0.0000e+00 - val_loss: 7.6829\n",
      "Epoch 86/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0227 - loss: 4.7140 - val_accuracy: 0.0000e+00 - val_loss: 7.6876\n",
      "Epoch 87/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0236 - loss: 4.7299 - val_accuracy: 0.0000e+00 - val_loss: 7.6921\n",
      "Epoch 88/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0245 - loss: 4.6892 - val_accuracy: 0.0000e+00 - val_loss: 7.6970\n",
      "Epoch 89/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0213 - loss: 4.7356 - val_accuracy: 0.0000e+00 - val_loss: 7.7095\n",
      "Epoch 90/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0220 - loss: 4.7280 - val_accuracy: 0.0000e+00 - val_loss: 7.7265\n",
      "Epoch 91/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0257 - loss: 4.7034 - val_accuracy: 0.0000e+00 - val_loss: 7.7347\n",
      "Epoch 92/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0236 - loss: 4.7302 - val_accuracy: 0.0000e+00 - val_loss: 7.7331\n",
      "Epoch 93/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0232 - loss: 4.6952 - val_accuracy: 0.0000e+00 - val_loss: 7.7325\n",
      "Epoch 94/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0243 - loss: 4.7385 - val_accuracy: 0.0000e+00 - val_loss: 7.7304\n",
      "Epoch 95/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.0237 - loss: 4.6930 - val_accuracy: 0.0000e+00 - val_loss: 7.7267\n",
      "Epoch 96/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0237 - loss: 4.7757 - val_accuracy: 0.0000e+00 - val_loss: 7.7240\n",
      "Epoch 97/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0241 - loss: 4.7275 - val_accuracy: 0.0000e+00 - val_loss: 7.7224\n",
      "Epoch 98/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0228 - loss: 4.7276 - val_accuracy: 0.0000e+00 - val_loss: 7.7274\n",
      "Epoch 99/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0227 - loss: 4.7525 - val_accuracy: 0.0000e+00 - val_loss: 7.7347\n",
      "Epoch 100/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0208 - loss: 4.7280 - val_accuracy: 0.0000e+00 - val_loss: 7.7432\n",
      "Epoch 101/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0220 - loss: 4.7223 - val_accuracy: 0.0000e+00 - val_loss: 7.7522\n",
      "Epoch 102/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0262 - loss: 4.7167 - val_accuracy: 0.0000e+00 - val_loss: 7.7513\n",
      "Epoch 103/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0195 - loss: 4.7297 - val_accuracy: 0.0000e+00 - val_loss: 7.7451\n",
      "Epoch 104/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0233 - loss: 4.7066 - val_accuracy: 0.0000e+00 - val_loss: 7.7629\n",
      "Epoch 105/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0227 - loss: 4.7092 - val_accuracy: 0.0000e+00 - val_loss: 7.7801\n",
      "Epoch 106/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0230 - loss: 4.7163 - val_accuracy: 0.0000e+00 - val_loss: 7.7952\n",
      "Epoch 107/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0254 - loss: 4.7106 - val_accuracy: 0.0000e+00 - val_loss: 7.8028\n",
      "Epoch 108/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0232 - loss: 4.7068 - val_accuracy: 0.0000e+00 - val_loss: 7.7984\n",
      "Epoch 109/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0219 - loss: 4.7047 - val_accuracy: 0.0000e+00 - val_loss: 7.7907\n",
      "Epoch 110/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0233 - loss: 4.7404 - val_accuracy: 0.0000e+00 - val_loss: 7.7897\n",
      "Epoch 111/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0221 - loss: 4.7367 - val_accuracy: 0.0000e+00 - val_loss: 7.7923\n",
      "Epoch 112/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0230 - loss: 4.7358 - val_accuracy: 0.0000e+00 - val_loss: 7.7906\n",
      "Epoch 113/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0236 - loss: 4.7164 - val_accuracy: 0.0000e+00 - val_loss: 7.7795\n",
      "Epoch 114/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0236 - loss: 4.7266 - val_accuracy: 0.0000e+00 - val_loss: 7.7803\n",
      "Epoch 115/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0229 - loss: 4.7204 - val_accuracy: 0.0000e+00 - val_loss: 7.7807\n",
      "Epoch 116/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0228 - loss: 4.7328 - val_accuracy: 0.0000e+00 - val_loss: 7.7783\n",
      "Epoch 117/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0227 - loss: 4.7726 - val_accuracy: 0.0000e+00 - val_loss: 7.7796\n",
      "Epoch 118/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0204 - loss: 4.7312 - val_accuracy: 0.0000e+00 - val_loss: 7.7858\n",
      "Epoch 119/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0238 - loss: 4.7312 - val_accuracy: 0.0000e+00 - val_loss: 7.7953\n",
      "Epoch 120/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0233 - loss: 4.7145 - val_accuracy: 0.0000e+00 - val_loss: 7.8032\n",
      "Epoch 121/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0248 - loss: 4.7376 - val_accuracy: 0.0000e+00 - val_loss: 7.8126\n",
      "Epoch 122/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0239 - loss: 4.6715 - val_accuracy: 0.0000e+00 - val_loss: 7.8136\n",
      "Epoch 123/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0213 - loss: 4.7078 - val_accuracy: 0.0000e+00 - val_loss: 7.8107\n",
      "Epoch 124/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0234 - loss: 4.6606 - val_accuracy: 0.0000e+00 - val_loss: 7.8121\n",
      "Epoch 125/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0226 - loss: 4.7229 - val_accuracy: 0.0000e+00 - val_loss: 7.8241\n",
      "Epoch 126/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0229 - loss: 4.6786 - val_accuracy: 0.0000e+00 - val_loss: 7.8365\n",
      "Epoch 127/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0244 - loss: 4.6851 - val_accuracy: 0.0000e+00 - val_loss: 7.8343\n",
      "Epoch 128/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0198 - loss: 4.7229 - val_accuracy: 0.0000e+00 - val_loss: 7.8248\n",
      "Epoch 129/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0233 - loss: 4.7086 - val_accuracy: 0.0000e+00 - val_loss: 7.8360\n",
      "Epoch 130/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0212 - loss: 4.7160 - val_accuracy: 0.0000e+00 - val_loss: 7.8524\n",
      "Epoch 131/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0232 - loss: 4.7255 - val_accuracy: 0.0000e+00 - val_loss: 7.8628\n",
      "Epoch 132/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0229 - loss: 4.7091 - val_accuracy: 0.0000e+00 - val_loss: 7.8702\n",
      "Epoch 133/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0228 - loss: 4.7261 - val_accuracy: 0.0000e+00 - val_loss: 7.8718\n",
      "Epoch 134/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0235 - loss: 4.7047 - val_accuracy: 0.0000e+00 - val_loss: 7.8694\n",
      "Epoch 135/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0223 - loss: 4.7223 - val_accuracy: 0.0000e+00 - val_loss: 7.8809\n",
      "Epoch 136/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0252 - loss: 4.7049 - val_accuracy: 0.0000e+00 - val_loss: 7.8874\n",
      "Epoch 137/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0248 - loss: 4.7093 - val_accuracy: 0.0000e+00 - val_loss: 7.8883\n",
      "Epoch 138/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0255 - loss: 4.6880 - val_accuracy: 0.0000e+00 - val_loss: 7.9008\n",
      "Epoch 139/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0241 - loss: 4.6874 - val_accuracy: 0.0000e+00 - val_loss: 7.9083\n",
      "Epoch 140/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0251 - loss: 4.7103 - val_accuracy: 0.0000e+00 - val_loss: 7.9027\n",
      "Epoch 141/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0252 - loss: 4.6834 - val_accuracy: 0.0000e+00 - val_loss: 7.8944\n",
      "Epoch 142/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0261 - loss: 4.6796 - val_accuracy: 0.0000e+00 - val_loss: 7.9116\n",
      "Epoch 143/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0266 - loss: 4.7514 - val_accuracy: 0.0000e+00 - val_loss: 7.8954\n",
      "Epoch 144/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0265 - loss: 4.6690 - val_accuracy: 0.0000e+00 - val_loss: 7.8731\n",
      "Epoch 145/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0238 - loss: 4.7221 - val_accuracy: 0.0000e+00 - val_loss: 7.8561\n",
      "Epoch 146/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0248 - loss: 4.7038 - val_accuracy: 0.0000e+00 - val_loss: 7.8570\n",
      "Epoch 147/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0291 - loss: 4.6837 - val_accuracy: 0.0000e+00 - val_loss: 7.8667\n",
      "Epoch 148/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0267 - loss: 4.6740 - val_accuracy: 0.0000e+00 - val_loss: 7.8678\n",
      "Epoch 149/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0237 - loss: 4.6784 - val_accuracy: 0.0000e+00 - val_loss: 7.8614\n",
      "Epoch 150/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0239 - loss: 4.6679 - val_accuracy: 0.0000e+00 - val_loss: 7.8551\n",
      "Epoch 151/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0259 - loss: 4.7359 - val_accuracy: 0.0000e+00 - val_loss: 7.8553\n",
      "Epoch 152/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0245 - loss: 4.6892 - val_accuracy: 0.0000e+00 - val_loss: 7.8745\n",
      "Epoch 153/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0261 - loss: 4.6545 - val_accuracy: 0.0000e+00 - val_loss: 7.8988\n",
      "Epoch 154/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0269 - loss: 4.6453 - val_accuracy: 0.0000e+00 - val_loss: 7.9157\n",
      "Epoch 155/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0238 - loss: 4.7150 - val_accuracy: 0.0000e+00 - val_loss: 7.8738\n",
      "Epoch 156/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0258 - loss: 4.6989 - val_accuracy: 0.0000e+00 - val_loss: 7.8715\n",
      "Epoch 157/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0237 - loss: 4.6857 - val_accuracy: 0.0000e+00 - val_loss: 7.8788\n",
      "Epoch 158/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0249 - loss: 4.6852 - val_accuracy: 0.0000e+00 - val_loss: 7.9001\n",
      "Epoch 159/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0271 - loss: 4.6865 - val_accuracy: 0.0000e+00 - val_loss: 7.9167\n",
      "Epoch 160/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0250 - loss: 4.6586 - val_accuracy: 0.0000e+00 - val_loss: 7.9139\n",
      "Epoch 161/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0264 - loss: 4.6926 - val_accuracy: 0.0019 - val_loss: 7.8924\n",
      "Epoch 162/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0271 - loss: 4.7059 - val_accuracy: 0.0019 - val_loss: 7.8968\n",
      "Epoch 163/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0266 - loss: 4.6271 - val_accuracy: 0.0019 - val_loss: 7.9068\n",
      "Epoch 164/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0272 - loss: 4.6735 - val_accuracy: 0.0019 - val_loss: 7.9103\n",
      "Epoch 165/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0299 - loss: 4.6610 - val_accuracy: 0.0038 - val_loss: 7.9028\n",
      "Epoch 166/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0291 - loss: 4.6780 - val_accuracy: 0.0019 - val_loss: 7.9031\n",
      "Epoch 167/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0284 - loss: 4.6683 - val_accuracy: 0.0019 - val_loss: 7.9103\n",
      "Epoch 168/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0248 - loss: 4.6786 - val_accuracy: 0.0019 - val_loss: 7.8580\n",
      "Epoch 169/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0242 - loss: 4.7184 - val_accuracy: 0.0019 - val_loss: 7.9311\n",
      "Epoch 170/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0300 - loss: 4.6657 - val_accuracy: 0.0019 - val_loss: 7.9399\n",
      "Epoch 171/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0297 - loss: 4.6567 - val_accuracy: 0.0019 - val_loss: 7.9344\n",
      "Epoch 172/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0238 - loss: 4.6561 - val_accuracy: 0.0038 - val_loss: 7.9155\n",
      "Epoch 173/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0284 - loss: 4.6595 - val_accuracy: 0.0019 - val_loss: 7.9479\n",
      "Epoch 174/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0319 - loss: 4.6932 - val_accuracy: 0.0019 - val_loss: 7.9674\n",
      "Epoch 175/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0288 - loss: 4.6789 - val_accuracy: 0.0019 - val_loss: 7.9661\n",
      "Epoch 176/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0287 - loss: 4.6554 - val_accuracy: 0.0019 - val_loss: 7.9492\n",
      "Epoch 177/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0281 - loss: 4.6559 - val_accuracy: 0.0019 - val_loss: 7.9245\n",
      "Epoch 178/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0293 - loss: 4.6503 - val_accuracy: 0.0038 - val_loss: 7.9215\n",
      "Epoch 179/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0314 - loss: 4.6529 - val_accuracy: 0.0038 - val_loss: 7.9343\n",
      "Epoch 180/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0311 - loss: 4.6727 - val_accuracy: 0.0019 - val_loss: 7.9421\n",
      "Epoch 181/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0304 - loss: 4.6950 - val_accuracy: 0.0019 - val_loss: 7.9345\n",
      "Epoch 182/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0324 - loss: 4.6612 - val_accuracy: 0.0096 - val_loss: 7.9381\n",
      "Epoch 183/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0258 - loss: 4.6578 - val_accuracy: 0.0057 - val_loss: 7.9359\n",
      "Epoch 184/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0263 - loss: 4.6675 - val_accuracy: 0.0019 - val_loss: 7.9501\n",
      "Epoch 185/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0293 - loss: 4.6774 - val_accuracy: 0.0019 - val_loss: 7.9720\n",
      "Epoch 186/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0307 - loss: 4.6394 - val_accuracy: 0.0019 - val_loss: 7.9876\n",
      "Epoch 187/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0282 - loss: 4.6326 - val_accuracy: 0.0019 - val_loss: 7.9910\n",
      "Epoch 188/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0264 - loss: 4.6890 - val_accuracy: 0.0019 - val_loss: 7.9864\n",
      "Epoch 189/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0275 - loss: 4.6498 - val_accuracy: 0.0019 - val_loss: 7.9855\n",
      "Epoch 190/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0304 - loss: 4.6362 - val_accuracy: 0.0019 - val_loss: 7.9827\n",
      "Epoch 191/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0320 - loss: 4.6263 - val_accuracy: 0.0019 - val_loss: 7.9841\n",
      "Epoch 192/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0276 - loss: 4.6462 - val_accuracy: 0.0077 - val_loss: 7.9783\n",
      "Epoch 193/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0298 - loss: 4.6293 - val_accuracy: 0.0153 - val_loss: 7.9639\n",
      "Epoch 194/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0293 - loss: 4.6447 - val_accuracy: 0.0134 - val_loss: 7.9496\n",
      "Epoch 195/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0299 - loss: 4.6389 - val_accuracy: 0.0134 - val_loss: 7.9444\n",
      "Epoch 196/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0294 - loss: 4.6460 - val_accuracy: 0.0153 - val_loss: 7.9514\n",
      "Epoch 197/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0322 - loss: 4.6101 - val_accuracy: 0.0153 - val_loss: 7.9611\n",
      "Epoch 198/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0295 - loss: 4.6420 - val_accuracy: 0.0134 - val_loss: 7.9628\n",
      "Epoch 199/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0284 - loss: 4.6738 - val_accuracy: 0.0134 - val_loss: 7.9622\n",
      "Epoch 200/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0293 - loss: 4.6256 - val_accuracy: 0.0096 - val_loss: 7.9721\n",
      "Epoch 201/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0271 - loss: 4.5776 - val_accuracy: 0.0019 - val_loss: 7.9737\n",
      "Epoch 202/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0239 - loss: 4.6436 - val_accuracy: 0.0019 - val_loss: 7.9790\n",
      "Epoch 203/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0301 - loss: 4.5941 - val_accuracy: 0.0019 - val_loss: 7.9777\n",
      "Epoch 204/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0284 - loss: 4.6093 - val_accuracy: 0.0019 - val_loss: 7.9893\n",
      "Epoch 205/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0265 - loss: 4.5980 - val_accuracy: 0.0019 - val_loss: 8.0094\n",
      "Epoch 206/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0284 - loss: 4.6235 - val_accuracy: 0.0019 - val_loss: 8.0223\n",
      "Epoch 207/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0298 - loss: 4.5696 - val_accuracy: 0.0019 - val_loss: 8.0257\n",
      "Epoch 208/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0299 - loss: 4.6055 - val_accuracy: 0.0019 - val_loss: 8.0304\n",
      "Epoch 209/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0296 - loss: 4.5788 - val_accuracy: 0.0019 - val_loss: 8.0278\n",
      "Epoch 210/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0282 - loss: 4.5938 - val_accuracy: 0.0134 - val_loss: 8.0117\n",
      "Epoch 211/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0265 - loss: 4.6096 - val_accuracy: 0.0134 - val_loss: 8.0157\n",
      "Epoch 212/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0268 - loss: 4.6226 - val_accuracy: 0.0153 - val_loss: 8.0407\n",
      "Epoch 213/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0278 - loss: 4.5979 - val_accuracy: 0.0153 - val_loss: 8.0460\n",
      "Epoch 214/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0336 - loss: 4.5291 - val_accuracy: 0.0134 - val_loss: 8.0404\n",
      "Epoch 215/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0314 - loss: 4.5869 - val_accuracy: 0.0134 - val_loss: 8.0371\n",
      "Epoch 216/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0280 - loss: 4.5791 - val_accuracy: 0.0134 - val_loss: 8.0400\n",
      "Epoch 217/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0281 - loss: 4.5945 - val_accuracy: 0.0153 - val_loss: 8.0477\n",
      "Epoch 218/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0275 - loss: 4.5901 - val_accuracy: 0.0153 - val_loss: 8.0539\n",
      "Epoch 219/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0307 - loss: 4.5883 - val_accuracy: 0.0153 - val_loss: 8.0403\n",
      "Epoch 220/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0287 - loss: 4.5780 - val_accuracy: 0.0134 - val_loss: 8.0384\n",
      "Epoch 221/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0294 - loss: 4.6174 - val_accuracy: 0.0153 - val_loss: 8.0589\n",
      "Epoch 222/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0349 - loss: 4.6050 - val_accuracy: 0.0153 - val_loss: 8.0667\n",
      "Epoch 223/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0313 - loss: 4.5369 - val_accuracy: 0.0134 - val_loss: 8.0637\n",
      "Epoch 224/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0273 - loss: 4.5805 - val_accuracy: 0.0153 - val_loss: 8.0735\n",
      "Epoch 225/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0294 - loss: 4.5611 - val_accuracy: 0.0153 - val_loss: 8.0886\n",
      "Epoch 226/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0321 - loss: 4.5502 - val_accuracy: 0.0153 - val_loss: 8.0911\n",
      "Epoch 227/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0317 - loss: 4.5643 - val_accuracy: 0.0153 - val_loss: 8.0896\n",
      "Epoch 228/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0310 - loss: 4.5646 - val_accuracy: 0.0153 - val_loss: 8.0888\n",
      "Epoch 229/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0327 - loss: 4.5524 - val_accuracy: 0.0153 - val_loss: 8.0853\n",
      "Epoch 230/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0294 - loss: 4.5722 - val_accuracy: 0.0153 - val_loss: 8.0868\n",
      "Epoch 231/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5s/step - accuracy: 0.0333 - loss: 4.5650 - val_accuracy: 0.0153 - val_loss: 8.0964\n",
      "Epoch 232/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0339 - loss: 4.5616 - val_accuracy: 0.0153 - val_loss: 8.0981\n",
      "Epoch 233/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0295 - loss: 4.5529 - val_accuracy: 0.0153 - val_loss: 8.0966\n",
      "Epoch 234/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0296 - loss: 4.5581 - val_accuracy: 0.0153 - val_loss: 8.0939\n",
      "Epoch 235/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0326 - loss: 4.5481 - val_accuracy: 0.0153 - val_loss: 8.0745\n",
      "Epoch 236/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0270 - loss: 4.5713 - val_accuracy: 0.0134 - val_loss: 8.0634\n",
      "Epoch 237/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0307 - loss: 4.5743 - val_accuracy: 0.0153 - val_loss: 8.1542\n",
      "Epoch 238/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0245 - loss: 4.6352 - val_accuracy: 0.0153 - val_loss: 8.1635\n",
      "Epoch 239/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0253 - loss: 4.5880 - val_accuracy: 0.0134 - val_loss: 8.1367\n",
      "Epoch 240/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0318 - loss: 4.5742 - val_accuracy: 0.0019 - val_loss: 8.0860\n",
      "Epoch 241/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0287 - loss: 4.5934 - val_accuracy: 0.0019 - val_loss: 8.0106\n",
      "Epoch 242/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0271 - loss: 4.6050 - val_accuracy: 0.0019 - val_loss: 8.0331\n",
      "Epoch 243/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0317 - loss: 4.6000 - val_accuracy: 0.0077 - val_loss: 8.0637\n",
      "Epoch 244/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0303 - loss: 4.5502 - val_accuracy: 0.0096 - val_loss: 8.0911\n",
      "Epoch 245/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0290 - loss: 4.5788 - val_accuracy: 0.0172 - val_loss: 8.0909\n",
      "Epoch 246/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0344 - loss: 4.5647 - val_accuracy: 0.0115 - val_loss: 8.0202\n",
      "Epoch 247/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.0333 - loss: 4.5762 - val_accuracy: 0.0153 - val_loss: 8.0174\n",
      "Epoch 248/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0328 - loss: 4.5683 - val_accuracy: 0.0134 - val_loss: 8.0330\n",
      "Epoch 249/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0328 - loss: 4.5734 - val_accuracy: 0.0153 - val_loss: 8.0510\n",
      "Epoch 250/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0328 - loss: 4.5256 - val_accuracy: 0.0153 - val_loss: 8.0595\n",
      "Epoch 251/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0332 - loss: 4.5601 - val_accuracy: 0.0153 - val_loss: 8.0543\n",
      "Epoch 252/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0310 - loss: 4.5548 - val_accuracy: 0.0153 - val_loss: 8.0377\n",
      "Epoch 253/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0311 - loss: 4.5489 - val_accuracy: 0.0153 - val_loss: 8.0313\n",
      "Epoch 254/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0306 - loss: 4.5042 - val_accuracy: 0.0153 - val_loss: 8.0292\n",
      "Epoch 255/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0333 - loss: 4.5187 - val_accuracy: 0.0153 - val_loss: 8.0307\n",
      "Epoch 256/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0289 - loss: 4.5284 - val_accuracy: 0.0153 - val_loss: 8.0122\n",
      "Epoch 257/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0340 - loss: 4.5548 - val_accuracy: 0.0153 - val_loss: 7.9965\n",
      "Epoch 258/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0308 - loss: 4.5299 - val_accuracy: 0.0153 - val_loss: 7.9996\n",
      "Epoch 259/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0323 - loss: 4.5239 - val_accuracy: 0.0153 - val_loss: 8.0147\n",
      "Epoch 260/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0325 - loss: 4.5279 - val_accuracy: 0.0153 - val_loss: 8.0215\n",
      "Epoch 261/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0297 - loss: 4.5207 - val_accuracy: 0.0153 - val_loss: 8.0244\n",
      "Epoch 262/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0321 - loss: 4.5182 - val_accuracy: 0.0134 - val_loss: 8.0397\n",
      "Epoch 263/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0316 - loss: 4.5480 - val_accuracy: 0.0153 - val_loss: 8.0562\n",
      "Epoch 264/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0276 - loss: 4.5658 - val_accuracy: 0.0153 - val_loss: 8.0624\n",
      "Epoch 265/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0348 - loss: 4.5131 - val_accuracy: 0.0153 - val_loss: 8.0679\n",
      "Epoch 266/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0310 - loss: 4.4785 - val_accuracy: 0.0153 - val_loss: 8.0691\n",
      "Epoch 267/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0322 - loss: 4.4920 - val_accuracy: 0.0172 - val_loss: 8.0593\n",
      "Epoch 268/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0350 - loss: 4.4961 - val_accuracy: 0.0172 - val_loss: 8.0499\n",
      "Epoch 269/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0342 - loss: 4.4910 - val_accuracy: 0.0172 - val_loss: 8.0430\n",
      "Epoch 270/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0330 - loss: 4.4984 - val_accuracy: 0.0172 - val_loss: 8.0322\n",
      "Epoch 271/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0328 - loss: 4.4926 - val_accuracy: 0.0096 - val_loss: 8.0367\n",
      "Epoch 272/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0331 - loss: 4.4890 - val_accuracy: 0.0172 - val_loss: 8.0561\n",
      "Epoch 273/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0332 - loss: 4.5117 - val_accuracy: 0.0172 - val_loss: 8.0617\n",
      "Epoch 274/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0335 - loss: 4.4969 - val_accuracy: 0.0172 - val_loss: 8.0671\n",
      "Epoch 275/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0336 - loss: 4.4941 - val_accuracy: 0.0172 - val_loss: 8.0821\n",
      "Epoch 276/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0333 - loss: 4.4947 - val_accuracy: 0.0172 - val_loss: 8.0839\n",
      "Epoch 277/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0324 - loss: 4.5053 - val_accuracy: 0.0172 - val_loss: 8.0883\n",
      "Epoch 278/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0356 - loss: 4.4948 - val_accuracy: 0.0172 - val_loss: 8.1188\n",
      "Epoch 279/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0316 - loss: 4.5026 - val_accuracy: 0.0172 - val_loss: 8.1318\n",
      "Epoch 280/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.0333 - loss: 4.5166 - val_accuracy: 0.0172 - val_loss: 8.1140\n",
      "Epoch 281/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0358 - loss: 4.4745 - val_accuracy: 0.0172 - val_loss: 8.1214\n",
      "Epoch 282/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0366 - loss: 4.4695 - val_accuracy: 0.0172 - val_loss: 8.1419\n",
      "Epoch 283/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0319 - loss: 4.4951 - val_accuracy: 0.0153 - val_loss: 8.1285\n",
      "Epoch 284/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0349 - loss: 4.4039 - val_accuracy: 0.0134 - val_loss: 8.1172\n",
      "Epoch 285/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0307 - loss: 4.5010 - val_accuracy: 0.0057 - val_loss: 8.1105\n",
      "Epoch 286/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0390 - loss: 4.4412 - val_accuracy: 0.0172 - val_loss: 8.1140\n",
      "Epoch 287/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0358 - loss: 4.4554 - val_accuracy: 0.0172 - val_loss: 8.1194\n",
      "Epoch 288/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0349 - loss: 4.4755 - val_accuracy: 0.0172 - val_loss: 8.1000\n",
      "Epoch 289/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0365 - loss: 4.4486 - val_accuracy: 0.0172 - val_loss: 8.1032\n",
      "Epoch 290/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0335 - loss: 4.4616 - val_accuracy: 0.0172 - val_loss: 8.1056\n",
      "Epoch 291/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0348 - loss: 4.4429 - val_accuracy: 0.0172 - val_loss: 8.1027\n",
      "Epoch 292/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0321 - loss: 4.4228 - val_accuracy: 0.0172 - val_loss: 8.0932\n",
      "Epoch 293/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0365 - loss: 4.4199 - val_accuracy: 0.0172 - val_loss: 8.1175\n",
      "Epoch 294/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0331 - loss: 4.4309 - val_accuracy: 0.0172 - val_loss: 8.1296\n",
      "Epoch 295/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0322 - loss: 4.4311 - val_accuracy: 0.0153 - val_loss: 8.1148\n",
      "Epoch 296/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0317 - loss: 4.4251 - val_accuracy: 0.0153 - val_loss: 8.1207\n",
      "Epoch 297/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0332 - loss: 4.4053 - val_accuracy: 0.0153 - val_loss: 8.1381\n",
      "Epoch 298/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0368 - loss: 4.4155 - val_accuracy: 0.0153 - val_loss: 8.1396\n",
      "Epoch 299/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0391 - loss: 4.4154 - val_accuracy: 0.0153 - val_loss: 8.1444\n",
      "Epoch 300/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0375 - loss: 4.4198 - val_accuracy: 0.0153 - val_loss: 8.1484\n",
      "Epoch 301/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0401 - loss: 4.4128 - val_accuracy: 0.0153 - val_loss: 8.1477\n",
      "Epoch 302/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0401 - loss: 4.4048 - val_accuracy: 0.0153 - val_loss: 8.1616\n",
      "Epoch 303/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0357 - loss: 4.4237 - val_accuracy: 0.0153 - val_loss: 8.1771\n",
      "Epoch 304/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0353 - loss: 4.3827 - val_accuracy: 0.0153 - val_loss: 8.1791\n",
      "Epoch 305/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0362 - loss: 4.4367 - val_accuracy: 0.0153 - val_loss: 8.1775\n",
      "Epoch 306/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0354 - loss: 4.4432 - val_accuracy: 0.0153 - val_loss: 8.1853\n",
      "Epoch 307/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0351 - loss: 4.4314 - val_accuracy: 0.0153 - val_loss: 8.1864\n",
      "Epoch 308/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0369 - loss: 4.4006 - val_accuracy: 0.0153 - val_loss: 8.1920\n",
      "Epoch 309/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0329 - loss: 4.3929 - val_accuracy: 0.0153 - val_loss: 8.1995\n",
      "Epoch 310/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0360 - loss: 4.3995 - val_accuracy: 0.0153 - val_loss: 8.2010\n",
      "Epoch 311/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0363 - loss: 4.3695 - val_accuracy: 0.0153 - val_loss: 8.2103\n",
      "Epoch 312/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0356 - loss: 4.4037 - val_accuracy: 0.0077 - val_loss: 8.1966\n",
      "Epoch 313/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0404 - loss: 4.3797 - val_accuracy: 0.0077 - val_loss: 8.2107\n",
      "Epoch 314/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0419 - loss: 4.3736 - val_accuracy: 0.0077 - val_loss: 8.2198\n",
      "Epoch 315/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0349 - loss: 4.4032 - val_accuracy: 0.0057 - val_loss: 8.2132\n",
      "Epoch 316/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0415 - loss: 4.3602 - val_accuracy: 0.0057 - val_loss: 8.2166\n",
      "Epoch 317/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0358 - loss: 4.3891 - val_accuracy: 0.0077 - val_loss: 8.2395\n",
      "Epoch 318/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0390 - loss: 4.3786 - val_accuracy: 0.0077 - val_loss: 8.2230\n",
      "Epoch 319/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0357 - loss: 4.3753 - val_accuracy: 0.0077 - val_loss: 8.2114\n",
      "Epoch 320/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0370 - loss: 4.4313 - val_accuracy: 0.0077 - val_loss: 8.2134\n",
      "Epoch 321/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0405 - loss: 4.3803 - val_accuracy: 0.0077 - val_loss: 8.2285\n",
      "Epoch 322/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0430 - loss: 4.3379 - val_accuracy: 0.0077 - val_loss: 8.2379\n",
      "Epoch 323/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0412 - loss: 4.3421 - val_accuracy: 0.0077 - val_loss: 8.2385\n",
      "Epoch 324/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0392 - loss: 4.3825 - val_accuracy: 0.0077 - val_loss: 8.2353\n",
      "Epoch 325/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0423 - loss: 4.3547 - val_accuracy: 0.0077 - val_loss: 8.2348\n",
      "Epoch 326/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0396 - loss: 4.3544 - val_accuracy: 0.0077 - val_loss: 8.2394\n",
      "Epoch 327/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0333 - loss: 4.3501 - val_accuracy: 0.0077 - val_loss: 8.2328\n",
      "Epoch 328/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0384 - loss: 4.3678 - val_accuracy: 0.0077 - val_loss: 8.2317\n",
      "Epoch 329/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0378 - loss: 4.3390 - val_accuracy: 0.0077 - val_loss: 8.2365\n",
      "Epoch 330/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.0417 - loss: 4.3332 - val_accuracy: 0.0077 - val_loss: 8.2391\n",
      "Epoch 331/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.0398 - loss: 4.3489 - val_accuracy: 0.0077 - val_loss: 8.2437\n",
      "Epoch 332/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0363 - loss: 4.3798 - val_accuracy: 0.0077 - val_loss: 8.2509\n",
      "Epoch 333/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0406 - loss: 4.3059 - val_accuracy: 0.0077 - val_loss: 8.2588\n",
      "Epoch 334/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0418 - loss: 4.3167 - val_accuracy: 0.0057 - val_loss: 8.2642\n",
      "Epoch 335/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0428 - loss: 4.3514 - val_accuracy: 0.0077 - val_loss: 8.2777\n",
      "Epoch 336/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0432 - loss: 4.3191 - val_accuracy: 0.0077 - val_loss: 8.2888\n",
      "Epoch 337/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0410 - loss: 4.3313 - val_accuracy: 0.0057 - val_loss: 8.2929\n",
      "Epoch 338/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0410 - loss: 4.3053 - val_accuracy: 0.0077 - val_loss: 8.2996\n",
      "Epoch 339/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0416 - loss: 4.3250 - val_accuracy: 0.0077 - val_loss: 8.3231\n",
      "Epoch 340/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0405 - loss: 4.3432 - val_accuracy: 0.0077 - val_loss: 8.3048\n",
      "Epoch 341/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0429 - loss: 4.2760 - val_accuracy: 0.0077 - val_loss: 8.3019\n",
      "Epoch 342/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0420 - loss: 4.3047 - val_accuracy: 0.0153 - val_loss: 8.3059\n",
      "Epoch 343/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0397 - loss: 4.3033 - val_accuracy: 0.0153 - val_loss: 8.3166\n",
      "Epoch 344/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0422 - loss: 4.2978 - val_accuracy: 0.0077 - val_loss: 8.3145\n",
      "Epoch 345/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0408 - loss: 4.2914 - val_accuracy: 0.0077 - val_loss: 8.3184\n",
      "Epoch 346/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0424 - loss: 4.2711 - val_accuracy: 0.0077 - val_loss: 8.3115\n",
      "Epoch 347/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0396 - loss: 4.2896 - val_accuracy: 0.0077 - val_loss: 8.3139\n",
      "Epoch 348/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0450 - loss: 4.2968 - val_accuracy: 0.0077 - val_loss: 8.3218\n",
      "Epoch 349/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0368 - loss: 4.3299 - val_accuracy: 0.0077 - val_loss: 8.3272\n",
      "Epoch 350/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0405 - loss: 4.2831 - val_accuracy: 0.0077 - val_loss: 8.3200\n",
      "Epoch 351/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0422 - loss: 4.2969 - val_accuracy: 0.0077 - val_loss: 8.3246\n",
      "Epoch 352/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0450 - loss: 4.2862 - val_accuracy: 0.0077 - val_loss: 8.3327\n",
      "Epoch 353/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0464 - loss: 4.2799 - val_accuracy: 0.0115 - val_loss: 8.3313\n",
      "Epoch 354/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0452 - loss: 4.2968 - val_accuracy: 0.0115 - val_loss: 8.3190\n",
      "Epoch 355/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0428 - loss: 4.2883 - val_accuracy: 0.0134 - val_loss: 8.3141\n",
      "Epoch 356/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0403 - loss: 4.2897 - val_accuracy: 0.0115 - val_loss: 8.3221\n",
      "Epoch 357/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0434 - loss: 4.2719 - val_accuracy: 0.0115 - val_loss: 8.3330\n",
      "Epoch 358/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0415 - loss: 4.2469 - val_accuracy: 0.0115 - val_loss: 8.3348\n",
      "Epoch 359/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0429 - loss: 4.2597 - val_accuracy: 0.0115 - val_loss: 8.3346\n",
      "Epoch 360/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0409 - loss: 4.2734 - val_accuracy: 0.0115 - val_loss: 8.3434\n",
      "Epoch 361/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0457 - loss: 4.2769 - val_accuracy: 0.0115 - val_loss: 8.3510\n",
      "Epoch 362/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0440 - loss: 4.2763 - val_accuracy: 0.0115 - val_loss: 8.3660\n",
      "Epoch 363/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0476 - loss: 4.2261 - val_accuracy: 0.0115 - val_loss: 8.3656\n",
      "Epoch 364/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0454 - loss: 4.2032 - val_accuracy: 0.0115 - val_loss: 8.3744\n",
      "Epoch 365/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0475 - loss: 4.2443 - val_accuracy: 0.0134 - val_loss: 8.3885\n",
      "Epoch 366/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0366 - loss: 4.2816 - val_accuracy: 0.0115 - val_loss: 8.3784\n",
      "Epoch 367/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0453 - loss: 4.2384 - val_accuracy: 0.0115 - val_loss: 8.3667\n",
      "Epoch 368/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0474 - loss: 4.2426 - val_accuracy: 0.0115 - val_loss: 8.3703\n",
      "Epoch 369/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0472 - loss: 4.2564 - val_accuracy: 0.0115 - val_loss: 8.3817\n",
      "Epoch 370/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0446 - loss: 4.2609 - val_accuracy: 0.0115 - val_loss: 8.3903\n",
      "Epoch 371/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0451 - loss: 4.2009 - val_accuracy: 0.0115 - val_loss: 8.3956\n",
      "Epoch 372/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0451 - loss: 4.2224 - val_accuracy: 0.0115 - val_loss: 8.3967\n",
      "Epoch 373/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0454 - loss: 4.2370 - val_accuracy: 0.0192 - val_loss: 8.3877\n",
      "Epoch 374/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0444 - loss: 4.1694 - val_accuracy: 0.0192 - val_loss: 8.3896\n",
      "Epoch 375/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0447 - loss: 4.2250 - val_accuracy: 0.0192 - val_loss: 8.4024\n",
      "Epoch 376/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0424 - loss: 4.2846 - val_accuracy: 0.0192 - val_loss: 8.4023\n",
      "Epoch 377/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0447 - loss: 4.2372 - val_accuracy: 0.0172 - val_loss: 8.3913\n",
      "Epoch 378/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0426 - loss: 4.2531 - val_accuracy: 0.0192 - val_loss: 8.3911\n",
      "Epoch 379/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0481 - loss: 4.2163 - val_accuracy: 0.0211 - val_loss: 8.3765\n",
      "Epoch 380/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0466 - loss: 4.2434 - val_accuracy: 0.0230 - val_loss: 8.3583\n",
      "Epoch 381/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0473 - loss: 4.2010 - val_accuracy: 0.0153 - val_loss: 8.3487\n",
      "Epoch 382/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0463 - loss: 4.2145 - val_accuracy: 0.0153 - val_loss: 8.3556\n",
      "Epoch 383/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0437 - loss: 4.2461 - val_accuracy: 0.0172 - val_loss: 8.3690\n",
      "Epoch 384/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0390 - loss: 4.2821 - val_accuracy: 0.0172 - val_loss: 8.3746\n",
      "Epoch 385/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0443 - loss: 4.1617 - val_accuracy: 0.0153 - val_loss: 8.3666\n",
      "Epoch 386/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0492 - loss: 4.1929 - val_accuracy: 0.0172 - val_loss: 8.3656\n",
      "Epoch 387/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0461 - loss: 4.2159 - val_accuracy: 0.0153 - val_loss: 8.3804\n",
      "Epoch 388/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0457 - loss: 4.2130 - val_accuracy: 0.0153 - val_loss: 8.3832\n",
      "Epoch 389/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0487 - loss: 4.2014 - val_accuracy: 0.0172 - val_loss: 8.3809\n",
      "Epoch 390/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0507 - loss: 4.1692 - val_accuracy: 0.0153 - val_loss: 8.3917\n",
      "Epoch 391/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0424 - loss: 4.2281 - val_accuracy: 0.0172 - val_loss: 8.3932\n",
      "Epoch 392/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0437 - loss: 4.1681 - val_accuracy: 0.0153 - val_loss: 8.3898\n",
      "Epoch 393/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0465 - loss: 4.1559 - val_accuracy: 0.0134 - val_loss: 8.3863\n",
      "Epoch 394/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0477 - loss: 4.1911 - val_accuracy: 0.0134 - val_loss: 8.3904\n",
      "Epoch 395/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0507 - loss: 4.1730 - val_accuracy: 0.0134 - val_loss: 8.3989\n",
      "Epoch 396/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0432 - loss: 4.1855 - val_accuracy: 0.0134 - val_loss: 8.4016\n",
      "Epoch 397/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0471 - loss: 4.2063 - val_accuracy: 0.0153 - val_loss: 8.4140\n",
      "Epoch 398/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0498 - loss: 4.1790 - val_accuracy: 0.0134 - val_loss: 8.4263\n",
      "Epoch 399/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0505 - loss: 4.1860 - val_accuracy: 0.0134 - val_loss: 8.4281\n",
      "Epoch 400/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0485 - loss: 4.1814 - val_accuracy: 0.0134 - val_loss: 8.4333\n",
      "Epoch 401/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0504 - loss: 4.0861 - val_accuracy: 0.0153 - val_loss: 8.4223\n",
      "Epoch 402/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0521 - loss: 4.1668 - val_accuracy: 0.0172 - val_loss: 8.4055\n",
      "Epoch 403/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0466 - loss: 4.1619 - val_accuracy: 0.0192 - val_loss: 8.4180\n",
      "Epoch 404/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0428 - loss: 4.1707 - val_accuracy: 0.0153 - val_loss: 8.4353\n",
      "Epoch 405/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0487 - loss: 4.1789 - val_accuracy: 0.0153 - val_loss: 8.4373\n",
      "Epoch 406/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0445 - loss: 4.1548 - val_accuracy: 0.0134 - val_loss: 8.4277\n",
      "Epoch 407/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0509 - loss: 4.1311 - val_accuracy: 0.0153 - val_loss: 8.4137\n",
      "Epoch 408/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0471 - loss: 4.1559 - val_accuracy: 0.0153 - val_loss: 8.4055\n",
      "Epoch 409/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0488 - loss: 4.1020 - val_accuracy: 0.0153 - val_loss: 8.3997\n",
      "Epoch 410/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0452 - loss: 4.1585 - val_accuracy: 0.0115 - val_loss: 8.4135\n",
      "Epoch 411/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0446 - loss: 4.1540 - val_accuracy: 0.0134 - val_loss: 8.4136\n",
      "Epoch 412/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0452 - loss: 4.1916 - val_accuracy: 0.0134 - val_loss: 8.4142\n",
      "Epoch 413/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0491 - loss: 4.1441 - val_accuracy: 0.0134 - val_loss: 8.4238\n",
      "Epoch 414/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0502 - loss: 4.1399 - val_accuracy: 0.0134 - val_loss: 8.4288\n",
      "Epoch 415/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0432 - loss: 4.1532 - val_accuracy: 0.0115 - val_loss: 8.4318\n",
      "Epoch 416/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0496 - loss: 4.1005 - val_accuracy: 0.0134 - val_loss: 8.4238\n",
      "Epoch 417/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0516 - loss: 4.1325 - val_accuracy: 0.0134 - val_loss: 8.4219\n",
      "Epoch 418/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0510 - loss: 4.0994 - val_accuracy: 0.0153 - val_loss: 8.4181\n",
      "Epoch 419/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0490 - loss: 4.1248 - val_accuracy: 0.0134 - val_loss: 8.4197\n",
      "Epoch 420/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0498 - loss: 4.1210 - val_accuracy: 0.0153 - val_loss: 8.3221\n",
      "Epoch 421/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0482 - loss: 4.1442 - val_accuracy: 0.0172 - val_loss: 8.3851\n",
      "Epoch 422/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0511 - loss: 4.1309 - val_accuracy: 0.0172 - val_loss: 8.4391\n",
      "Epoch 423/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0464 - loss: 4.1571 - val_accuracy: 0.0230 - val_loss: 8.4300\n",
      "Epoch 424/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0470 - loss: 4.1196 - val_accuracy: 0.0230 - val_loss: 8.4525\n",
      "Epoch 425/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0478 - loss: 4.1582 - val_accuracy: 0.0230 - val_loss: 8.4665\n",
      "Epoch 426/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0456 - loss: 4.1090 - val_accuracy: 0.0211 - val_loss: 8.4653\n",
      "Epoch 427/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0504 - loss: 4.1165 - val_accuracy: 0.0211 - val_loss: 8.4526\n",
      "Epoch 428/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0466 - loss: 4.1273 - val_accuracy: 0.0211 - val_loss: 8.4449\n",
      "Epoch 429/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0471 - loss: 4.1010 - val_accuracy: 0.0192 - val_loss: 8.4516\n",
      "Epoch 430/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0498 - loss: 4.0401 - val_accuracy: 0.0192 - val_loss: 8.4621\n",
      "Epoch 431/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0483 - loss: 4.1057 - val_accuracy: 0.0172 - val_loss: 8.4577\n",
      "Epoch 432/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0466 - loss: 4.1436 - val_accuracy: 0.0134 - val_loss: 8.4544\n",
      "Epoch 433/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0494 - loss: 4.1031 - val_accuracy: 0.0134 - val_loss: 8.4455\n",
      "Epoch 434/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0493 - loss: 4.0983 - val_accuracy: 0.0134 - val_loss: 8.4395\n",
      "Epoch 435/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0508 - loss: 4.1273 - val_accuracy: 0.0134 - val_loss: 8.4462\n",
      "Epoch 436/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0512 - loss: 4.0776 - val_accuracy: 0.0134 - val_loss: 8.4473\n",
      "Epoch 437/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0494 - loss: 4.1009 - val_accuracy: 0.0134 - val_loss: 8.4393\n",
      "Epoch 438/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0531 - loss: 4.1107 - val_accuracy: 0.0134 - val_loss: 8.4342\n",
      "Epoch 439/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.0503 - loss: 4.1298 - val_accuracy: 0.0153 - val_loss: 8.4408\n",
      "Epoch 440/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0508 - loss: 4.0858 - val_accuracy: 0.0153 - val_loss: 8.4513\n",
      "Epoch 441/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0596 - loss: 4.1201 - val_accuracy: 0.0153 - val_loss: 8.4422\n",
      "Epoch 442/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0599 - loss: 4.0809 - val_accuracy: 0.0134 - val_loss: 8.3696\n",
      "Epoch 443/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0518 - loss: 4.1091 - val_accuracy: 0.0134 - val_loss: 8.3262\n",
      "Epoch 444/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0605 - loss: 4.0687 - val_accuracy: 0.0134 - val_loss: 8.2781\n",
      "Epoch 445/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0625 - loss: 4.1025 - val_accuracy: 0.0134 - val_loss: 8.3158\n",
      "Epoch 446/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0590 - loss: 4.0648 - val_accuracy: 0.0153 - val_loss: 8.3266\n",
      "Epoch 447/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0647 - loss: 4.0589 - val_accuracy: 0.0172 - val_loss: 8.3337\n",
      "Epoch 448/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0524 - loss: 4.0983 - val_accuracy: 0.0153 - val_loss: 8.3432\n",
      "Epoch 449/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0552 - loss: 4.0974 - val_accuracy: 0.0172 - val_loss: 8.3596\n",
      "Epoch 450/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0515 - loss: 4.1042 - val_accuracy: 0.0172 - val_loss: 8.3605\n",
      "Epoch 451/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0480 - loss: 4.0863 - val_accuracy: 0.0192 - val_loss: 8.3607\n",
      "Epoch 452/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.0468 - loss: 4.0109 - val_accuracy: 0.0172 - val_loss: 8.3244\n",
      "Epoch 453/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0545 - loss: 4.0499 - val_accuracy: 0.0172 - val_loss: 8.3695\n",
      "Epoch 454/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0544 - loss: 3.9920 - val_accuracy: 0.0153 - val_loss: 8.3598\n",
      "Epoch 455/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0482 - loss: 4.0421 - val_accuracy: 0.0153 - val_loss: 8.3264\n",
      "Epoch 456/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0593 - loss: 4.0359 - val_accuracy: 0.0153 - val_loss: 8.3114\n",
      "Epoch 457/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0528 - loss: 4.0626 - val_accuracy: 0.0153 - val_loss: 8.3122\n",
      "Epoch 458/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0569 - loss: 4.0576 - val_accuracy: 0.0134 - val_loss: 8.3373\n",
      "Epoch 459/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0601 - loss: 4.0578 - val_accuracy: 0.0172 - val_loss: 8.3213\n",
      "Epoch 460/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0921 - loss: 4.0731 - val_accuracy: 0.0134 - val_loss: 8.3124\n",
      "Epoch 461/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1085 - loss: 4.0735 - val_accuracy: 0.0134 - val_loss: 8.3251\n",
      "Epoch 462/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0719 - loss: 4.0974 - val_accuracy: 0.0153 - val_loss: 8.3600\n",
      "Epoch 463/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0667 - loss: 4.0454 - val_accuracy: 0.0172 - val_loss: 8.3825\n",
      "Epoch 464/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0742 - loss: 4.0483 - val_accuracy: 0.0192 - val_loss: 8.3829\n",
      "Epoch 465/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0728 - loss: 4.0689 - val_accuracy: 0.0192 - val_loss: 8.3690\n",
      "Epoch 466/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0689 - loss: 4.0445 - val_accuracy: 0.0192 - val_loss: 8.3345\n",
      "Epoch 467/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0650 - loss: 4.0512 - val_accuracy: 0.0192 - val_loss: 8.3459\n",
      "Epoch 468/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0641 - loss: 4.0453 - val_accuracy: 0.0153 - val_loss: 8.3625\n",
      "Epoch 469/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0597 - loss: 4.0352 - val_accuracy: 0.0134 - val_loss: 8.3318\n",
      "Epoch 470/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0593 - loss: 4.0248 - val_accuracy: 0.0134 - val_loss: 8.3254\n",
      "Epoch 471/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0595 - loss: 4.0763 - val_accuracy: 0.0134 - val_loss: 8.3402\n",
      "Epoch 472/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0778 - loss: 4.0594 - val_accuracy: 0.0134 - val_loss: 8.3691\n",
      "Epoch 473/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0915 - loss: 4.0647 - val_accuracy: 0.0134 - val_loss: 8.3388\n",
      "Epoch 474/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0810 - loss: 4.0142 - val_accuracy: 0.0172 - val_loss: 8.3449\n",
      "Epoch 475/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0892 - loss: 4.0602 - val_accuracy: 0.0172 - val_loss: 8.3542\n",
      "Epoch 476/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1001 - loss: 4.0337 - val_accuracy: 0.0172 - val_loss: 8.3363\n",
      "Epoch 477/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0750 - loss: 4.0515 - val_accuracy: 0.0172 - val_loss: 8.3410\n",
      "Epoch 478/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0800 - loss: 4.0346 - val_accuracy: 0.0172 - val_loss: 8.3622\n",
      "Epoch 479/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0594 - loss: 4.0124 - val_accuracy: 0.0192 - val_loss: 8.3597\n",
      "Epoch 480/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0580 - loss: 4.0544 - val_accuracy: 0.0211 - val_loss: 8.3146\n",
      "Epoch 481/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0592 - loss: 4.0341 - val_accuracy: 0.0192 - val_loss: 8.3244\n",
      "Epoch 482/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0574 - loss: 4.0314 - val_accuracy: 0.0172 - val_loss: 8.3832\n",
      "Epoch 483/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0616 - loss: 3.9901 - val_accuracy: 0.0153 - val_loss: 8.4060\n",
      "Epoch 484/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0647 - loss: 4.0116 - val_accuracy: 0.0172 - val_loss: 8.4119\n",
      "Epoch 485/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0839 - loss: 4.0309 - val_accuracy: 0.0172 - val_loss: 8.4092\n",
      "Epoch 486/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0843 - loss: 4.0050 - val_accuracy: 0.0153 - val_loss: 8.4029\n",
      "Epoch 487/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0730 - loss: 4.0053 - val_accuracy: 0.0172 - val_loss: 8.4134\n",
      "Epoch 488/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.0808 - loss: 4.0110 - val_accuracy: 0.0192 - val_loss: 8.4260\n",
      "Epoch 489/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0964 - loss: 3.9672 - val_accuracy: 0.0134 - val_loss: 8.4422\n",
      "Epoch 490/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.1194 - loss: 3.9493 - val_accuracy: 0.0134 - val_loss: 8.4290\n",
      "Epoch 491/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1184 - loss: 3.9721 - val_accuracy: 0.0134 - val_loss: 8.4118\n",
      "Epoch 492/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0999 - loss: 3.9666 - val_accuracy: 0.0134 - val_loss: 8.3958\n",
      "Epoch 493/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0911 - loss: 3.9384 - val_accuracy: 0.0134 - val_loss: 8.3982\n",
      "Epoch 494/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0832 - loss: 3.9543 - val_accuracy: 0.0134 - val_loss: 8.4017\n",
      "Epoch 495/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0890 - loss: 3.8541 - val_accuracy: 0.0134 - val_loss: 8.4155\n",
      "Epoch 496/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0916 - loss: 3.9058 - val_accuracy: 0.0134 - val_loss: 8.4086\n",
      "Epoch 497/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0942 - loss: 3.9412 - val_accuracy: 0.0134 - val_loss: 8.3947\n",
      "Epoch 498/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1029 - loss: 3.8910 - val_accuracy: 0.0134 - val_loss: 8.3900\n",
      "Epoch 499/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1178 - loss: 3.9015 - val_accuracy: 0.0134 - val_loss: 8.3525\n",
      "Epoch 500/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1219 - loss: 3.8810 - val_accuracy: 0.0134 - val_loss: 8.3446\n",
      "Epoch 501/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1434 - loss: 3.8823 - val_accuracy: 0.0134 - val_loss: 8.3679\n",
      "Epoch 502/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1256 - loss: 3.8233 - val_accuracy: 0.0134 - val_loss: 8.3656\n",
      "Epoch 503/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0964 - loss: 3.9019 - val_accuracy: 0.0134 - val_loss: 8.3760\n",
      "Epoch 504/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0940 - loss: 3.9230 - val_accuracy: 0.0134 - val_loss: 8.3916\n",
      "Epoch 505/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0961 - loss: 3.9061 - val_accuracy: 0.0134 - val_loss: 8.3651\n",
      "Epoch 506/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1123 - loss: 3.8830 - val_accuracy: 0.0134 - val_loss: 8.3715\n",
      "Epoch 507/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1239 - loss: 3.8601 - val_accuracy: 0.0134 - val_loss: 8.3996\n",
      "Epoch 508/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1177 - loss: 3.8458 - val_accuracy: 0.0134 - val_loss: 8.4080\n",
      "Epoch 509/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1166 - loss: 3.8752 - val_accuracy: 0.0134 - val_loss: 8.4132\n",
      "Epoch 510/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.0906 - loss: 3.8631 - val_accuracy: 0.0134 - val_loss: 8.4159\n",
      "Epoch 511/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1082 - loss: 3.8634 - val_accuracy: 0.0134 - val_loss: 8.4236\n",
      "Epoch 512/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1068 - loss: 3.8855 - val_accuracy: 0.0134 - val_loss: 8.4304\n",
      "Epoch 513/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0995 - loss: 3.8705 - val_accuracy: 0.0134 - val_loss: 8.4523\n",
      "Epoch 514/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1067 - loss: 3.8382 - val_accuracy: 0.0134 - val_loss: 8.4488\n",
      "Epoch 515/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1331 - loss: 3.8279 - val_accuracy: 0.0134 - val_loss: 8.4529\n",
      "Epoch 516/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1332 - loss: 3.8114 - val_accuracy: 0.0134 - val_loss: 8.4644\n",
      "Epoch 517/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1411 - loss: 3.7878 - val_accuracy: 0.0134 - val_loss: 8.4615\n",
      "Epoch 518/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1699 - loss: 3.8153 - val_accuracy: 0.0153 - val_loss: 8.4545\n",
      "Epoch 519/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1774 - loss: 3.8193 - val_accuracy: 0.0153 - val_loss: 8.4448\n",
      "Epoch 520/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1857 - loss: 3.8151 - val_accuracy: 0.0153 - val_loss: 8.4422\n",
      "Epoch 521/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1748 - loss: 3.8089 - val_accuracy: 0.0153 - val_loss: 8.4401\n",
      "Epoch 522/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1540 - loss: 3.7833 - val_accuracy: 0.0192 - val_loss: 8.4472\n",
      "Epoch 523/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1814 - loss: 3.7797 - val_accuracy: 0.0192 - val_loss: 8.4600\n",
      "Epoch 524/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1662 - loss: 3.8042 - val_accuracy: 0.0172 - val_loss: 8.4689\n",
      "Epoch 525/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1393 - loss: 3.7784 - val_accuracy: 0.0153 - val_loss: 8.4745\n",
      "Epoch 526/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1226 - loss: 3.8071 - val_accuracy: 0.0192 - val_loss: 8.4709\n",
      "Epoch 527/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1362 - loss: 3.7722 - val_accuracy: 0.0172 - val_loss: 8.4969\n",
      "Epoch 528/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1362 - loss: 3.7923 - val_accuracy: 0.0172 - val_loss: 8.5207\n",
      "Epoch 529/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1444 - loss: 3.7806 - val_accuracy: 0.0192 - val_loss: 8.5296\n",
      "Epoch 530/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1142 - loss: 3.7687 - val_accuracy: 0.0172 - val_loss: 8.5267\n",
      "Epoch 531/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.1129 - loss: 3.7425 - val_accuracy: 0.0172 - val_loss: 8.5079\n",
      "Epoch 532/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1157 - loss: 3.7109 - val_accuracy: 0.0172 - val_loss: 8.5017\n",
      "Epoch 533/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1120 - loss: 3.7153 - val_accuracy: 0.0153 - val_loss: 8.4936\n",
      "Epoch 534/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1406 - loss: 3.7521 - val_accuracy: 0.0153 - val_loss: 8.4823\n",
      "Epoch 535/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1210 - loss: 3.7006 - val_accuracy: 0.0172 - val_loss: 8.4744\n",
      "Epoch 536/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1282 - loss: 3.7178 - val_accuracy: 0.0172 - val_loss: 8.4708\n",
      "Epoch 537/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1506 - loss: 3.7683 - val_accuracy: 0.0172 - val_loss: 8.4658\n",
      "Epoch 538/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1597 - loss: 3.7526 - val_accuracy: 0.0172 - val_loss: 8.4777\n",
      "Epoch 539/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1422 - loss: 3.7204 - val_accuracy: 0.0172 - val_loss: 8.4628\n",
      "Epoch 540/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1381 - loss: 3.7485 - val_accuracy: 0.0172 - val_loss: 8.4791\n",
      "Epoch 541/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1527 - loss: 3.7315 - val_accuracy: 0.0153 - val_loss: 8.4909\n",
      "Epoch 542/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1595 - loss: 3.7554 - val_accuracy: 0.0172 - val_loss: 8.4939\n",
      "Epoch 543/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1290 - loss: 3.7104 - val_accuracy: 0.0172 - val_loss: 8.5060\n",
      "Epoch 544/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1544 - loss: 3.7173 - val_accuracy: 0.0153 - val_loss: 8.5197\n",
      "Epoch 545/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1637 - loss: 3.7058 - val_accuracy: 0.0172 - val_loss: 8.5393\n",
      "Epoch 546/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1424 - loss: 3.7001 - val_accuracy: 0.0153 - val_loss: 8.5492\n",
      "Epoch 547/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1332 - loss: 3.7011 - val_accuracy: 0.0172 - val_loss: 8.5500\n",
      "Epoch 548/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1629 - loss: 3.6912 - val_accuracy: 0.0153 - val_loss: 8.5400\n",
      "Epoch 549/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1784 - loss: 3.6889 - val_accuracy: 0.0172 - val_loss: 8.5515\n",
      "Epoch 550/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1773 - loss: 3.6502 - val_accuracy: 0.0153 - val_loss: 8.5794\n",
      "Epoch 551/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1552 - loss: 3.7055 - val_accuracy: 0.0153 - val_loss: 8.5908\n",
      "Epoch 552/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1825 - loss: 3.7097 - val_accuracy: 0.0153 - val_loss: 8.5953\n",
      "Epoch 553/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1966 - loss: 3.6921 - val_accuracy: 0.0153 - val_loss: 8.5946\n",
      "Epoch 554/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1571 - loss: 3.6543 - val_accuracy: 0.0153 - val_loss: 8.6019\n",
      "Epoch 555/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1541 - loss: 3.6708 - val_accuracy: 0.0153 - val_loss: 8.5793\n",
      "Epoch 556/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1533 - loss: 3.6323 - val_accuracy: 0.0172 - val_loss: 8.5705\n",
      "Epoch 557/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1791 - loss: 3.6422 - val_accuracy: 0.0172 - val_loss: 8.5742\n",
      "Epoch 558/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1793 - loss: 3.6472 - val_accuracy: 0.0153 - val_loss: 8.5704\n",
      "Epoch 559/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1584 - loss: 3.6603 - val_accuracy: 0.0153 - val_loss: 8.5630\n",
      "Epoch 560/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1412 - loss: 3.6745 - val_accuracy: 0.0153 - val_loss: 8.5590\n",
      "Epoch 561/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1765 - loss: 3.6351 - val_accuracy: 0.0153 - val_loss: 8.5677\n",
      "Epoch 562/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1690 - loss: 3.6450 - val_accuracy: 0.0172 - val_loss: 8.5924\n",
      "Epoch 563/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1656 - loss: 3.6175 - val_accuracy: 0.0172 - val_loss: 8.5956\n",
      "Epoch 564/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.1395 - loss: 3.6326 - val_accuracy: 0.0172 - val_loss: 8.5924\n",
      "Epoch 565/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1911 - loss: 3.5952 - val_accuracy: 0.0153 - val_loss: 8.5911\n",
      "Epoch 566/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2210 - loss: 3.6652 - val_accuracy: 0.0153 - val_loss: 8.5848\n",
      "Epoch 567/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1437 - loss: 3.5731 - val_accuracy: 0.0172 - val_loss: 8.5847\n",
      "Epoch 568/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1410 - loss: 3.6462 - val_accuracy: 0.0153 - val_loss: 8.5927\n",
      "Epoch 569/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1399 - loss: 3.6315 - val_accuracy: 0.0153 - val_loss: 8.6024\n",
      "Epoch 570/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1588 - loss: 3.5742 - val_accuracy: 0.0172 - val_loss: 8.6105\n",
      "Epoch 571/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1456 - loss: 3.6094 - val_accuracy: 0.0153 - val_loss: 8.6170\n",
      "Epoch 572/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.1477 - loss: 3.5534 - val_accuracy: 0.0172 - val_loss: 8.6193\n",
      "Epoch 573/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1495 - loss: 3.5885 - val_accuracy: 0.0153 - val_loss: 8.6165\n",
      "Epoch 574/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1667 - loss: 3.5504 - val_accuracy: 0.0172 - val_loss: 8.6129\n",
      "Epoch 575/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1440 - loss: 3.5784 - val_accuracy: 0.0115 - val_loss: 8.6122\n",
      "Epoch 576/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.1496 - loss: 3.6237 - val_accuracy: 0.0115 - val_loss: 8.6118\n",
      "Epoch 577/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2000 - loss: 3.5421 - val_accuracy: 0.0115 - val_loss: 8.6079\n",
      "Epoch 578/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1696 - loss: 3.5807 - val_accuracy: 0.0115 - val_loss: 8.6027\n",
      "Epoch 579/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1522 - loss: 3.5484 - val_accuracy: 0.0115 - val_loss: 8.6062\n",
      "Epoch 580/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1866 - loss: 3.5566 - val_accuracy: 0.0134 - val_loss: 8.6063\n",
      "Epoch 581/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1842 - loss: 3.5411 - val_accuracy: 0.0172 - val_loss: 8.5960\n",
      "Epoch 582/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1841 - loss: 3.5879 - val_accuracy: 0.0172 - val_loss: 8.5973\n",
      "Epoch 583/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1315 - loss: 3.5791 - val_accuracy: 0.0172 - val_loss: 8.6124\n",
      "Epoch 584/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1385 - loss: 3.5501 - val_accuracy: 0.0172 - val_loss: 8.6205\n",
      "Epoch 585/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.1416 - loss: 3.4916 - val_accuracy: 0.0153 - val_loss: 8.6228\n",
      "Epoch 586/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1362 - loss: 3.5303 - val_accuracy: 0.0153 - val_loss: 8.6248\n",
      "Epoch 587/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1438 - loss: 3.5315 - val_accuracy: 0.0153 - val_loss: 8.6246\n",
      "Epoch 588/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1823 - loss: 3.5411 - val_accuracy: 0.0172 - val_loss: 8.6252\n",
      "Epoch 589/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1753 - loss: 3.4956 - val_accuracy: 0.0172 - val_loss: 8.6303\n",
      "Epoch 590/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1443 - loss: 3.5142 - val_accuracy: 0.0172 - val_loss: 8.6056\n",
      "Epoch 591/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1882 - loss: 3.5147 - val_accuracy: 0.0172 - val_loss: 8.6518\n",
      "Epoch 592/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1757 - loss: 3.5053 - val_accuracy: 0.0172 - val_loss: 8.6641\n",
      "Epoch 593/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1626 - loss: 3.5357 - val_accuracy: 0.0172 - val_loss: 8.6708\n",
      "Epoch 594/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1736 - loss: 3.5277 - val_accuracy: 0.0172 - val_loss: 8.6471\n",
      "Epoch 595/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1586 - loss: 3.5246 - val_accuracy: 0.0172 - val_loss: 8.6464\n",
      "Epoch 596/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1586 - loss: 3.4991 - val_accuracy: 0.0134 - val_loss: 8.6527\n",
      "Epoch 597/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1710 - loss: 3.4972 - val_accuracy: 0.0115 - val_loss: 8.6572\n",
      "Epoch 598/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2180 - loss: 3.5077 - val_accuracy: 0.0115 - val_loss: 8.6568\n",
      "Epoch 599/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1508 - loss: 3.5005 - val_accuracy: 0.0115 - val_loss: 8.6677\n",
      "Epoch 600/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1446 - loss: 3.4726 - val_accuracy: 0.0115 - val_loss: 8.6817\n",
      "Epoch 601/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1537 - loss: 3.4863 - val_accuracy: 0.0115 - val_loss: 8.6959\n",
      "Epoch 602/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1812 - loss: 3.4611 - val_accuracy: 0.0115 - val_loss: 8.7267\n",
      "Epoch 603/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1534 - loss: 3.4721 - val_accuracy: 0.0153 - val_loss: 8.7341\n",
      "Epoch 604/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1827 - loss: 3.4951 - val_accuracy: 0.0172 - val_loss: 8.7332\n",
      "Epoch 605/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2132 - loss: 3.5375 - val_accuracy: 0.0153 - val_loss: 8.6998\n",
      "Epoch 606/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2210 - loss: 3.4604 - val_accuracy: 0.0172 - val_loss: 8.6976\n",
      "Epoch 607/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1899 - loss: 3.4146 - val_accuracy: 0.0153 - val_loss: 8.6796\n",
      "Epoch 608/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1693 - loss: 3.4919 - val_accuracy: 0.0153 - val_loss: 8.6852\n",
      "Epoch 609/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2039 - loss: 3.4546 - val_accuracy: 0.0153 - val_loss: 8.6872\n",
      "Epoch 610/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1483 - loss: 3.4470 - val_accuracy: 0.0172 - val_loss: 8.6915\n",
      "Epoch 611/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1570 - loss: 3.4281 - val_accuracy: 0.0153 - val_loss: 8.6961\n",
      "Epoch 612/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1425 - loss: 3.4545 - val_accuracy: 0.0172 - val_loss: 8.6969\n",
      "Epoch 613/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1308 - loss: 3.4294 - val_accuracy: 0.0172 - val_loss: 8.7040\n",
      "Epoch 614/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1545 - loss: 3.4712 - val_accuracy: 0.0172 - val_loss: 8.7100\n",
      "Epoch 615/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1852 - loss: 3.4808 - val_accuracy: 0.0172 - val_loss: 8.7148\n",
      "Epoch 616/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1714 - loss: 3.4094 - val_accuracy: 0.0153 - val_loss: 8.7206\n",
      "Epoch 617/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1796 - loss: 3.4043 - val_accuracy: 0.0153 - val_loss: 8.7183\n",
      "Epoch 618/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1691 - loss: 3.4075 - val_accuracy: 0.0172 - val_loss: 8.6980\n",
      "Epoch 619/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1661 - loss: 3.4588 - val_accuracy: 0.0153 - val_loss: 8.6906\n",
      "Epoch 620/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2095 - loss: 3.4263 - val_accuracy: 0.0153 - val_loss: 8.6899\n",
      "Epoch 621/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1733 - loss: 3.4185 - val_accuracy: 0.0153 - val_loss: 8.6967\n",
      "Epoch 622/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1452 - loss: 3.4351 - val_accuracy: 0.0172 - val_loss: 8.7051\n",
      "Epoch 623/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1525 - loss: 3.3808 - val_accuracy: 0.0153 - val_loss: 8.7168\n",
      "Epoch 624/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1818 - loss: 3.2881 - val_accuracy: 0.0172 - val_loss: 8.7241\n",
      "Epoch 625/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1870 - loss: 3.4144 - val_accuracy: 0.0153 - val_loss: 8.7332\n",
      "Epoch 626/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1766 - loss: 3.4068 - val_accuracy: 0.0172 - val_loss: 8.7408\n",
      "Epoch 627/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1696 - loss: 3.4015 - val_accuracy: 0.0172 - val_loss: 8.7445\n",
      "Epoch 628/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2352 - loss: 3.3669 - val_accuracy: 0.0153 - val_loss: 8.7464\n",
      "Epoch 629/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2349 - loss: 3.4243 - val_accuracy: 0.0172 - val_loss: 8.7505\n",
      "Epoch 630/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1924 - loss: 3.4327 - val_accuracy: 0.0172 - val_loss: 8.7528\n",
      "Epoch 631/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2011 - loss: 3.3715 - val_accuracy: 0.0153 - val_loss: 8.7497\n",
      "Epoch 632/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2028 - loss: 3.3764 - val_accuracy: 0.0153 - val_loss: 8.7421\n",
      "Epoch 633/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2307 - loss: 3.4044 - val_accuracy: 0.0153 - val_loss: 8.7319\n",
      "Epoch 634/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2056 - loss: 3.3902 - val_accuracy: 0.0172 - val_loss: 8.7328\n",
      "Epoch 635/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1923 - loss: 3.3782 - val_accuracy: 0.0153 - val_loss: 8.7369\n",
      "Epoch 636/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1500 - loss: 3.4071 - val_accuracy: 0.0172 - val_loss: 8.7355\n",
      "Epoch 637/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1664 - loss: 3.3726 - val_accuracy: 0.0153 - val_loss: 8.7357\n",
      "Epoch 638/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1674 - loss: 3.3774 - val_accuracy: 0.0153 - val_loss: 8.7361\n",
      "Epoch 639/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1766 - loss: 3.3673 - val_accuracy: 0.0153 - val_loss: 8.7461\n",
      "Epoch 640/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1673 - loss: 3.3619 - val_accuracy: 0.0172 - val_loss: 8.7647\n",
      "Epoch 641/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1433 - loss: 3.3445 - val_accuracy: 0.0172 - val_loss: 8.7741\n",
      "Epoch 642/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1450 - loss: 3.3510 - val_accuracy: 0.0172 - val_loss: 8.7797\n",
      "Epoch 643/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1757 - loss: 3.3710 - val_accuracy: 0.0172 - val_loss: 8.7851\n",
      "Epoch 644/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2043 - loss: 3.3510 - val_accuracy: 0.0172 - val_loss: 8.7926\n",
      "Epoch 645/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2069 - loss: 3.3427 - val_accuracy: 0.0172 - val_loss: 8.8010\n",
      "Epoch 646/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2206 - loss: 3.3408 - val_accuracy: 0.0172 - val_loss: 8.8077\n",
      "Epoch 647/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2071 - loss: 3.3315 - val_accuracy: 0.0172 - val_loss: 8.8105\n",
      "Epoch 648/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2323 - loss: 3.3400 - val_accuracy: 0.0153 - val_loss: 8.8137\n",
      "Epoch 649/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2354 - loss: 3.3512 - val_accuracy: 0.0153 - val_loss: 8.8188\n",
      "Epoch 650/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2039 - loss: 3.3422 - val_accuracy: 0.0153 - val_loss: 8.8201\n",
      "Epoch 651/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1880 - loss: 3.3050 - val_accuracy: 0.0153 - val_loss: 8.8183\n",
      "Epoch 652/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2112 - loss: 3.3253 - val_accuracy: 0.0172 - val_loss: 8.8126\n",
      "Epoch 653/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1552 - loss: 3.3463 - val_accuracy: 0.0153 - val_loss: 8.8128\n",
      "Epoch 654/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1503 - loss: 3.3398 - val_accuracy: 0.0153 - val_loss: 8.8120\n",
      "Epoch 655/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1550 - loss: 3.3109 - val_accuracy: 0.0153 - val_loss: 8.8094\n",
      "Epoch 656/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1511 - loss: 3.3321 - val_accuracy: 0.0153 - val_loss: 8.8052\n",
      "Epoch 657/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1714 - loss: 3.3017 - val_accuracy: 0.0153 - val_loss: 8.8031\n",
      "Epoch 658/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2007 - loss: 3.3256 - val_accuracy: 0.0134 - val_loss: 8.8024\n",
      "Epoch 659/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2164 - loss: 3.3227 - val_accuracy: 0.0134 - val_loss: 8.8039\n",
      "Epoch 660/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1791 - loss: 3.3059 - val_accuracy: 0.0153 - val_loss: 8.8120\n",
      "Epoch 661/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1822 - loss: 3.3141 - val_accuracy: 0.0172 - val_loss: 8.8242\n",
      "Epoch 662/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2061 - loss: 3.3106 - val_accuracy: 0.0172 - val_loss: 8.8368\n",
      "Epoch 663/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1898 - loss: 3.2873 - val_accuracy: 0.0172 - val_loss: 8.8426\n",
      "Epoch 664/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2013 - loss: 3.2895 - val_accuracy: 0.0172 - val_loss: 8.8415\n",
      "Epoch 665/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1948 - loss: 3.2891 - val_accuracy: 0.0153 - val_loss: 8.8411\n",
      "Epoch 666/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.2210 - loss: 3.2959 - val_accuracy: 0.0153 - val_loss: 8.8424\n",
      "Epoch 667/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1721 - loss: 3.2963 - val_accuracy: 0.0153 - val_loss: 8.8347\n",
      "Epoch 668/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1930 - loss: 3.2501 - val_accuracy: 0.0172 - val_loss: 8.8335\n",
      "Epoch 669/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1992 - loss: 3.2569 - val_accuracy: 0.0153 - val_loss: 8.8338\n",
      "Epoch 670/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1915 - loss: 3.2685 - val_accuracy: 0.0172 - val_loss: 8.8341\n",
      "Epoch 671/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1633 - loss: 3.2531 - val_accuracy: 0.0172 - val_loss: 8.8236\n",
      "Epoch 672/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1969 - loss: 3.2687 - val_accuracy: 0.0172 - val_loss: 8.8201\n",
      "Epoch 673/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1887 - loss: 3.2277 - val_accuracy: 0.0172 - val_loss: 8.8368\n",
      "Epoch 674/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2059 - loss: 3.2839 - val_accuracy: 0.0172 - val_loss: 8.8381\n",
      "Epoch 675/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1862 - loss: 3.2790 - val_accuracy: 0.0153 - val_loss: 8.8517\n",
      "Epoch 676/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2047 - loss: 3.2781 - val_accuracy: 0.0153 - val_loss: 8.8576\n",
      "Epoch 677/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2058 - loss: 3.2447 - val_accuracy: 0.0172 - val_loss: 8.8573\n",
      "Epoch 678/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2116 - loss: 3.2596 - val_accuracy: 0.0172 - val_loss: 8.8541\n",
      "Epoch 679/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2318 - loss: 3.2500 - val_accuracy: 0.0172 - val_loss: 8.8529\n",
      "Epoch 680/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1756 - loss: 3.2764 - val_accuracy: 0.0153 - val_loss: 8.8525\n",
      "Epoch 681/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1874 - loss: 3.2546 - val_accuracy: 0.0153 - val_loss: 8.8545\n",
      "Epoch 682/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1880 - loss: 3.2182 - val_accuracy: 0.0172 - val_loss: 8.8552\n",
      "Epoch 683/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1983 - loss: 3.2165 - val_accuracy: 0.0172 - val_loss: 8.8599\n",
      "Epoch 684/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1814 - loss: 3.2635 - val_accuracy: 0.0172 - val_loss: 8.8601\n",
      "Epoch 685/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1610 - loss: 3.2018 - val_accuracy: 0.0172 - val_loss: 8.8606\n",
      "Epoch 686/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1977 - loss: 3.1625 - val_accuracy: 0.0153 - val_loss: 8.8651\n",
      "Epoch 687/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1930 - loss: 3.2662 - val_accuracy: 0.0172 - val_loss: 8.8686\n",
      "Epoch 688/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1595 - loss: 3.2549 - val_accuracy: 0.0172 - val_loss: 8.8775\n",
      "Epoch 689/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1662 - loss: 3.2195 - val_accuracy: 0.0172 - val_loss: 8.8712\n",
      "Epoch 690/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2001 - loss: 3.2361 - val_accuracy: 0.0172 - val_loss: 8.8676\n",
      "Epoch 691/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2001 - loss: 3.2355 - val_accuracy: 0.0172 - val_loss: 8.8678\n",
      "Epoch 692/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2047 - loss: 3.2201 - val_accuracy: 0.0192 - val_loss: 8.8702\n",
      "Epoch 693/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2375 - loss: 3.1873 - val_accuracy: 0.0172 - val_loss: 8.8772\n",
      "Epoch 694/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2308 - loss: 3.2112 - val_accuracy: 0.0172 - val_loss: 8.8836\n",
      "Epoch 695/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2152 - loss: 3.2046 - val_accuracy: 0.0172 - val_loss: 8.8899\n",
      "Epoch 696/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2004 - loss: 3.2133 - val_accuracy: 0.0153 - val_loss: 8.9018\n",
      "Epoch 697/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2836 - loss: 3.1792 - val_accuracy: 0.0172 - val_loss: 8.9066\n",
      "Epoch 698/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2048 - loss: 3.2285 - val_accuracy: 0.0172 - val_loss: 8.9075\n",
      "Epoch 699/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1888 - loss: 3.2384 - val_accuracy: 0.0134 - val_loss: 8.9127\n",
      "Epoch 700/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2646 - loss: 3.2149 - val_accuracy: 0.0153 - val_loss: 8.9141\n",
      "Epoch 701/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1972 - loss: 3.2248 - val_accuracy: 0.0153 - val_loss: 8.9089\n",
      "Epoch 702/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1566 - loss: 3.2130 - val_accuracy: 0.0211 - val_loss: 8.9153\n",
      "Epoch 703/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1969 - loss: 3.1866 - val_accuracy: 0.0211 - val_loss: 8.9130\n",
      "Epoch 704/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2452 - loss: 3.2434 - val_accuracy: 0.0096 - val_loss: 8.9059\n",
      "Epoch 705/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1877 - loss: 3.1905 - val_accuracy: 0.0096 - val_loss: 8.9009\n",
      "Epoch 706/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1984 - loss: 3.2034 - val_accuracy: 0.0172 - val_loss: 8.8920\n",
      "Epoch 707/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2304 - loss: 3.1923 - val_accuracy: 0.0192 - val_loss: 8.9036\n",
      "Epoch 708/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2192 - loss: 3.1835 - val_accuracy: 0.0172 - val_loss: 8.8935\n",
      "Epoch 709/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1799 - loss: 3.1857 - val_accuracy: 0.0172 - val_loss: 8.8895\n",
      "Epoch 710/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1738 - loss: 3.1992 - val_accuracy: 0.0192 - val_loss: 8.8817\n",
      "Epoch 711/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2067 - loss: 3.2089 - val_accuracy: 0.0172 - val_loss: 8.8789\n",
      "Epoch 712/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1948 - loss: 3.1966 - val_accuracy: 0.0153 - val_loss: 8.9041\n",
      "Epoch 713/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1585 - loss: 3.1939 - val_accuracy: 0.0172 - val_loss: 8.9172\n",
      "Epoch 714/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1881 - loss: 3.1853 - val_accuracy: 0.0172 - val_loss: 8.9189\n",
      "Epoch 715/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2205 - loss: 3.1635 - val_accuracy: 0.0192 - val_loss: 8.9207\n",
      "Epoch 716/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2336 - loss: 3.1323 - val_accuracy: 0.0192 - val_loss: 8.9245\n",
      "Epoch 717/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1837 - loss: 3.1653 - val_accuracy: 0.0211 - val_loss: 8.9272\n",
      "Epoch 718/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1826 - loss: 3.1382 - val_accuracy: 0.0172 - val_loss: 8.9349\n",
      "Epoch 719/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2079 - loss: 3.1465 - val_accuracy: 0.0192 - val_loss: 8.9367\n",
      "Epoch 720/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2489 - loss: 3.1470 - val_accuracy: 0.0211 - val_loss: 8.9477\n",
      "Epoch 721/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1992 - loss: 3.1481 - val_accuracy: 0.0192 - val_loss: 8.9675\n",
      "Epoch 722/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.1951 - loss: 3.1605 - val_accuracy: 0.0211 - val_loss: 8.9838\n",
      "Epoch 723/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2065 - loss: 3.1402 - val_accuracy: 0.0211 - val_loss: 8.9873\n",
      "Epoch 724/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2222 - loss: 3.1206 - val_accuracy: 0.0192 - val_loss: 8.9817\n",
      "Epoch 725/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2288 - loss: 3.1458 - val_accuracy: 0.0211 - val_loss: 8.9741\n",
      "Epoch 726/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2015 - loss: 3.1418 - val_accuracy: 0.0172 - val_loss: 8.9720\n",
      "Epoch 727/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2059 - loss: 3.1464 - val_accuracy: 0.0172 - val_loss: 8.9783\n",
      "Epoch 728/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2094 - loss: 3.1025 - val_accuracy: 0.0172 - val_loss: 8.9809\n",
      "Epoch 729/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2177 - loss: 3.1502 - val_accuracy: 0.0153 - val_loss: 8.9879\n",
      "Epoch 730/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1984 - loss: 3.1248 - val_accuracy: 0.0153 - val_loss: 8.9948\n",
      "Epoch 731/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - accuracy: 0.1872 - loss: 3.1095 - val_accuracy: 0.0211 - val_loss: 9.0038\n",
      "Epoch 732/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2373 - loss: 3.1069 - val_accuracy: 0.0192 - val_loss: 9.0103\n",
      "Epoch 733/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2456 - loss: 3.1089 - val_accuracy: 0.0192 - val_loss: 9.0129\n",
      "Epoch 734/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2025 - loss: 3.1182 - val_accuracy: 0.0192 - val_loss: 9.0102\n",
      "Epoch 735/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2048 - loss: 3.1335 - val_accuracy: 0.0211 - val_loss: 9.0094\n",
      "Epoch 736/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2449 - loss: 3.1139 - val_accuracy: 0.0211 - val_loss: 9.0083\n",
      "Epoch 737/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2473 - loss: 3.0612 - val_accuracy: 0.0192 - val_loss: 9.0046\n",
      "Epoch 738/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2112 - loss: 3.1248 - val_accuracy: 0.0192 - val_loss: 9.0001\n",
      "Epoch 739/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2355 - loss: 3.1014 - val_accuracy: 0.0192 - val_loss: 9.0000\n",
      "Epoch 740/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2380 - loss: 3.1102 - val_accuracy: 0.0153 - val_loss: 9.0087\n",
      "Epoch 741/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2077 - loss: 3.1183 - val_accuracy: 0.0211 - val_loss: 8.9754\n",
      "Epoch 742/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2170 - loss: 3.0919 - val_accuracy: 0.0230 - val_loss: 8.9476\n",
      "Epoch 743/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2271 - loss: 3.1124 - val_accuracy: 0.0230 - val_loss: 8.9274\n",
      "Epoch 744/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2099 - loss: 3.1032 - val_accuracy: 0.0192 - val_loss: 8.9372\n",
      "Epoch 745/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2369 - loss: 3.0582 - val_accuracy: 0.0192 - val_loss: 8.9446\n",
      "Epoch 746/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2467 - loss: 3.0744 - val_accuracy: 0.0211 - val_loss: 8.9530\n",
      "Epoch 747/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2025 - loss: 3.0758 - val_accuracy: 0.0192 - val_loss: 9.0058\n",
      "Epoch 748/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2281 - loss: 3.0872 - val_accuracy: 0.0192 - val_loss: 9.0243\n",
      "Epoch 749/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1978 - loss: 3.0740 - val_accuracy: 0.0192 - val_loss: 8.9930\n",
      "Epoch 750/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.1945 - loss: 3.0756 - val_accuracy: 0.0230 - val_loss: 8.9410\n",
      "Epoch 751/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2203 - loss: 3.0889 - val_accuracy: 0.0249 - val_loss: 8.9329\n",
      "Epoch 752/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2209 - loss: 3.0690 - val_accuracy: 0.0211 - val_loss: 8.9531\n",
      "Epoch 753/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1858 - loss: 3.0717 - val_accuracy: 0.0153 - val_loss: 8.9873\n",
      "Epoch 754/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1992 - loss: 3.1164 - val_accuracy: 0.0153 - val_loss: 8.9692\n",
      "Epoch 755/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2310 - loss: 3.1130 - val_accuracy: 0.0172 - val_loss: 8.9617\n",
      "Epoch 756/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2285 - loss: 3.0294 - val_accuracy: 0.0153 - val_loss: 8.9764\n",
      "Epoch 757/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2212 - loss: 3.1111 - val_accuracy: 0.0153 - val_loss: 8.9949\n",
      "Epoch 758/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1734 - loss: 3.0892 - val_accuracy: 0.0172 - val_loss: 9.0093\n",
      "Epoch 759/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.1979 - loss: 3.0441 - val_accuracy: 0.0153 - val_loss: 9.0078\n",
      "Epoch 760/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2001 - loss: 3.0512 - val_accuracy: 0.0153 - val_loss: 8.9910\n",
      "Epoch 761/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2282 - loss: 3.0399 - val_accuracy: 0.0172 - val_loss: 8.9741\n",
      "Epoch 762/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2190 - loss: 3.0643 - val_accuracy: 0.0192 - val_loss: 8.9546\n",
      "Epoch 763/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2400 - loss: 3.0590 - val_accuracy: 0.0211 - val_loss: 8.9536\n",
      "Epoch 764/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2245 - loss: 3.0737 - val_accuracy: 0.0211 - val_loss: 8.9622\n",
      "Epoch 765/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1755s\u001b[0m 5s/step - accuracy: 0.1894 - loss: 3.0025 - val_accuracy: 0.0192 - val_loss: 8.9889\n",
      "Epoch 766/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.1994 - loss: 3.0327 - val_accuracy: 0.0211 - val_loss: 9.0128\n",
      "Epoch 767/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2341 - loss: 3.0306 - val_accuracy: 0.0192 - val_loss: 9.0292\n",
      "Epoch 768/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6s/step - accuracy: 0.2207 - loss: 3.0532 - val_accuracy: 0.0192 - val_loss: 9.0434\n",
      "Epoch 769/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2162 - loss: 3.0548 - val_accuracy: 0.0211 - val_loss: 9.0516\n",
      "Epoch 770/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.1903 - loss: 3.0422 - val_accuracy: 0.0211 - val_loss: 9.0439\n",
      "Epoch 771/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.2400 - loss: 2.9948 - val_accuracy: 0.0211 - val_loss: 9.0262\n",
      "Epoch 772/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2602 - loss: 3.0541 - val_accuracy: 0.0192 - val_loss: 9.0104\n",
      "Epoch 773/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2221 - loss: 3.0357 - val_accuracy: 0.0172 - val_loss: 9.0182\n",
      "Epoch 774/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5s/step - accuracy: 0.2494 - loss: 2.9905 - val_accuracy: 0.0211 - val_loss: 9.0488\n",
      "Epoch 775/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2341 - loss: 3.0196 - val_accuracy: 0.0172 - val_loss: 9.0535\n",
      "Epoch 776/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2245 - loss: 3.0311 - val_accuracy: 0.0192 - val_loss: 9.0336\n",
      "Epoch 777/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2143 - loss: 3.0793 - val_accuracy: 0.0192 - val_loss: 9.0153\n",
      "Epoch 778/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2736 - loss: 3.0075 - val_accuracy: 0.0211 - val_loss: 8.9569\n",
      "Epoch 779/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2331 - loss: 3.0279 - val_accuracy: 0.0230 - val_loss: 8.9491\n",
      "Epoch 780/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2552 - loss: 3.0262 - val_accuracy: 0.0192 - val_loss: 8.9169\n",
      "Epoch 781/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2554 - loss: 3.0129 - val_accuracy: 0.0211 - val_loss: 8.9222\n",
      "Epoch 782/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2525 - loss: 3.0331 - val_accuracy: 0.0192 - val_loss: 8.9812\n",
      "Epoch 783/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.2657 - loss: 3.0513 - val_accuracy: 0.0211 - val_loss: 9.0114\n",
      "Epoch 784/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2673 - loss: 2.9555 - val_accuracy: 0.0192 - val_loss: 9.0289\n",
      "Epoch 785/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.2559 - loss: 2.9842 - val_accuracy: 0.0192 - val_loss: 9.0204\n",
      "Epoch 786/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2686 - loss: 2.9873 - val_accuracy: 0.0192 - val_loss: 9.0220\n",
      "Epoch 787/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2913 - loss: 2.9802 - val_accuracy: 0.0211 - val_loss: 9.0152\n",
      "Epoch 788/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2287 - loss: 3.0068 - val_accuracy: 0.0211 - val_loss: 9.0124\n",
      "Epoch 789/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2620 - loss: 2.9931 - val_accuracy: 0.0230 - val_loss: 9.0226\n",
      "Epoch 790/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2842 - loss: 3.0042 - val_accuracy: 0.0230 - val_loss: 9.0099\n",
      "Epoch 791/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2773 - loss: 2.9406 - val_accuracy: 0.0249 - val_loss: 8.9919\n",
      "Epoch 792/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2582 - loss: 3.0110 - val_accuracy: 0.0268 - val_loss: 8.9756\n",
      "Epoch 793/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2915 - loss: 2.9885 - val_accuracy: 0.0230 - val_loss: 8.9298\n",
      "Epoch 794/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2932 - loss: 2.9608 - val_accuracy: 0.0268 - val_loss: 8.9034\n",
      "Epoch 795/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5s/step - accuracy: 0.2811 - loss: 2.9976 - val_accuracy: 0.0287 - val_loss: 8.9295\n",
      "Epoch 796/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2831 - loss: 2.9762 - val_accuracy: 0.0249 - val_loss: 8.9565\n",
      "Epoch 797/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2666 - loss: 2.9753 - val_accuracy: 0.0230 - val_loss: 8.9372\n",
      "Epoch 798/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4s/step - accuracy: 0.2056 - loss: 2.9694 - val_accuracy: 0.0230 - val_loss: 8.9547\n",
      "Epoch 799/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.2544 - loss: 2.9949 - val_accuracy: 0.0249 - val_loss: 9.0194\n",
      "Epoch 800/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3158 - loss: 3.0062 - val_accuracy: 0.0249 - val_loss: 9.0345\n",
      "Epoch 801/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2603 - loss: 2.9726 - val_accuracy: 0.0249 - val_loss: 9.0389\n",
      "Epoch 802/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2599 - loss: 2.9699 - val_accuracy: 0.0211 - val_loss: 9.0675\n",
      "Epoch 803/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3092 - loss: 2.9783 - val_accuracy: 0.0211 - val_loss: 9.0866\n",
      "Epoch 804/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3157 - loss: 2.9885 - val_accuracy: 0.0211 - val_loss: 9.0566\n",
      "Epoch 805/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3094 - loss: 2.9827 - val_accuracy: 0.0192 - val_loss: 9.0587\n",
      "Epoch 806/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.2735 - loss: 2.9748 - val_accuracy: 0.0230 - val_loss: 9.0387\n",
      "Epoch 807/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2892 - loss: 2.9610 - val_accuracy: 0.0230 - val_loss: 9.0235\n",
      "Epoch 808/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2738 - loss: 2.9741 - val_accuracy: 0.0211 - val_loss: 9.0173\n",
      "Epoch 809/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2675 - loss: 2.9402 - val_accuracy: 0.0211 - val_loss: 9.0164\n",
      "Epoch 810/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2849 - loss: 2.9349 - val_accuracy: 0.0230 - val_loss: 9.0263\n",
      "Epoch 811/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3401 - loss: 2.9264 - val_accuracy: 0.0211 - val_loss: 9.0392\n",
      "Epoch 812/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3263 - loss: 2.9409 - val_accuracy: 0.0211 - val_loss: 9.0532\n",
      "Epoch 813/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3349 - loss: 2.9354 - val_accuracy: 0.0211 - val_loss: 9.0635\n",
      "Epoch 814/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.2821 - loss: 2.9322 - val_accuracy: 0.0230 - val_loss: 9.0587\n",
      "Epoch 815/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3074 - loss: 2.9051 - val_accuracy: 0.0249 - val_loss: 9.0460\n",
      "Epoch 816/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3139 - loss: 2.9354 - val_accuracy: 0.0230 - val_loss: 9.0356\n",
      "Epoch 817/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3176 - loss: 2.9329 - val_accuracy: 0.0172 - val_loss: 9.1355\n",
      "Epoch 818/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3071 - loss: 2.9036 - val_accuracy: 0.0192 - val_loss: 9.1516\n",
      "Epoch 819/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2748 - loss: 2.9428 - val_accuracy: 0.0192 - val_loss: 9.1395\n",
      "Epoch 820/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2849 - loss: 2.9648 - val_accuracy: 0.0192 - val_loss: 9.1437\n",
      "Epoch 821/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3019 - loss: 2.9182 - val_accuracy: 0.0211 - val_loss: 9.1271\n",
      "Epoch 822/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2515 - loss: 2.9663 - val_accuracy: 0.0211 - val_loss: 9.1117\n",
      "Epoch 823/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2901 - loss: 2.8979 - val_accuracy: 0.0192 - val_loss: 9.1048\n",
      "Epoch 824/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3022 - loss: 2.9062 - val_accuracy: 0.0192 - val_loss: 9.0928\n",
      "Epoch 825/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3219 - loss: 2.9378 - val_accuracy: 0.0211 - val_loss: 9.0835\n",
      "Epoch 826/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3312 - loss: 2.9280 - val_accuracy: 0.0192 - val_loss: 9.0901\n",
      "Epoch 827/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3202 - loss: 2.9404 - val_accuracy: 0.0192 - val_loss: 9.0871\n",
      "Epoch 828/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2976 - loss: 2.9521 - val_accuracy: 0.0211 - val_loss: 9.1061\n",
      "Epoch 829/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3245 - loss: 2.9414 - val_accuracy: 0.0192 - val_loss: 9.1367\n",
      "Epoch 830/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - accuracy: 0.3114 - loss: 2.9120 - val_accuracy: 0.0172 - val_loss: 9.1247\n",
      "Epoch 831/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2729 - loss: 2.9274 - val_accuracy: 0.0172 - val_loss: 9.1130\n",
      "Epoch 832/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.2899 - loss: 2.9306 - val_accuracy: 0.0172 - val_loss: 9.1065\n",
      "Epoch 833/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.3335 - loss: 2.9187 - val_accuracy: 0.0172 - val_loss: 9.0818\n",
      "Epoch 834/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3134 - loss: 2.8912 - val_accuracy: 0.0134 - val_loss: 8.9885\n",
      "Epoch 835/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3166 - loss: 2.9120 - val_accuracy: 0.0192 - val_loss: 9.0488\n",
      "Epoch 836/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3085 - loss: 2.8890 - val_accuracy: 0.0211 - val_loss: 9.0777\n",
      "Epoch 837/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3221 - loss: 2.8700 - val_accuracy: 0.0211 - val_loss: 9.0831\n",
      "Epoch 838/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2925 - loss: 2.9515 - val_accuracy: 0.0211 - val_loss: 9.0578\n",
      "Epoch 839/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2705 - loss: 2.9134 - val_accuracy: 0.0230 - val_loss: 9.0268\n",
      "Epoch 840/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3106 - loss: 2.8731 - val_accuracy: 0.0230 - val_loss: 8.9509\n",
      "Epoch 841/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3304 - loss: 2.9022 - val_accuracy: 0.0249 - val_loss: 8.9540\n",
      "Epoch 842/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3279 - loss: 2.8798 - val_accuracy: 0.0192 - val_loss: 9.0424\n",
      "Epoch 843/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3168 - loss: 2.9011 - val_accuracy: 0.0230 - val_loss: 8.9380\n",
      "Epoch 844/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3136 - loss: 2.8977 - val_accuracy: 0.0211 - val_loss: 8.9167\n",
      "Epoch 845/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3152 - loss: 2.8808 - val_accuracy: 0.0192 - val_loss: 8.9212\n",
      "Epoch 846/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3205 - loss: 2.8759 - val_accuracy: 0.0192 - val_loss: 8.9501\n",
      "Epoch 847/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3247 - loss: 2.8740 - val_accuracy: 0.0172 - val_loss: 8.9795\n",
      "Epoch 848/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3140 - loss: 2.8754 - val_accuracy: 0.0211 - val_loss: 8.9882\n",
      "Epoch 849/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2836 - loss: 2.8969 - val_accuracy: 0.0211 - val_loss: 8.9875\n",
      "Epoch 850/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3346 - loss: 2.8636 - val_accuracy: 0.0192 - val_loss: 9.0462\n",
      "Epoch 851/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3524 - loss: 2.8558 - val_accuracy: 0.0192 - val_loss: 9.0461\n",
      "Epoch 852/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3377 - loss: 2.8828 - val_accuracy: 0.0230 - val_loss: 8.9639\n",
      "Epoch 853/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3120 - loss: 2.8641 - val_accuracy: 0.0211 - val_loss: 8.9440\n",
      "Epoch 854/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2940 - loss: 2.8772 - val_accuracy: 0.0211 - val_loss: 8.9354\n",
      "Epoch 855/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3210 - loss: 2.8633 - val_accuracy: 0.0192 - val_loss: 8.9310\n",
      "Epoch 856/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3458 - loss: 2.8259 - val_accuracy: 0.0230 - val_loss: 8.9299\n",
      "Epoch 857/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.8252 - val_accuracy: 0.0192 - val_loss: 8.9391\n",
      "Epoch 858/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3083 - loss: 2.8166 - val_accuracy: 0.0192 - val_loss: 8.9432\n",
      "Epoch 859/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3301 - loss: 2.8600 - val_accuracy: 0.0211 - val_loss: 8.9474\n",
      "Epoch 860/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3246 - loss: 2.8684 - val_accuracy: 0.0230 - val_loss: 8.9479\n",
      "Epoch 861/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3263 - loss: 2.8782 - val_accuracy: 0.0249 - val_loss: 8.9584\n",
      "Epoch 862/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3539 - loss: 2.8513 - val_accuracy: 0.0249 - val_loss: 8.9666\n",
      "Epoch 863/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3142 - loss: 2.7776 - val_accuracy: 0.0230 - val_loss: 8.9955\n",
      "Epoch 864/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3251 - loss: 2.8466 - val_accuracy: 0.0230 - val_loss: 9.0266\n",
      "Epoch 865/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3357 - loss: 2.8633 - val_accuracy: 0.0249 - val_loss: 8.9624\n",
      "Epoch 866/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3399 - loss: 2.9028 - val_accuracy: 0.0249 - val_loss: 8.9476\n",
      "Epoch 867/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3482 - loss: 2.8369 - val_accuracy: 0.0230 - val_loss: 8.9291\n",
      "Epoch 868/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3475 - loss: 2.8452 - val_accuracy: 0.0211 - val_loss: 8.9166\n",
      "Epoch 869/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3169 - loss: 2.8277 - val_accuracy: 0.0192 - val_loss: 8.9704\n",
      "Epoch 870/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3311 - loss: 2.8675 - val_accuracy: 0.0230 - val_loss: 9.0224\n",
      "Epoch 871/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3585 - loss: 2.8017 - val_accuracy: 0.0211 - val_loss: 8.9760\n",
      "Epoch 872/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3163 - loss: 2.7722 - val_accuracy: 0.0192 - val_loss: 8.9591\n",
      "Epoch 873/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3271 - loss: 2.7949 - val_accuracy: 0.0230 - val_loss: 8.9597\n",
      "Epoch 874/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3775 - loss: 2.8126 - val_accuracy: 0.0249 - val_loss: 8.9562\n",
      "Epoch 875/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3569 - loss: 2.8127 - val_accuracy: 0.0249 - val_loss: 8.9597\n",
      "Epoch 876/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3480 - loss: 2.7953 - val_accuracy: 0.0230 - val_loss: 8.9863\n",
      "Epoch 877/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3411 - loss: 2.8062 - val_accuracy: 0.0249 - val_loss: 8.8936\n",
      "Epoch 878/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3560 - loss: 2.8372 - val_accuracy: 0.0287 - val_loss: 8.8705\n",
      "Epoch 879/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3444 - loss: 2.8380 - val_accuracy: 0.0268 - val_loss: 8.8990\n",
      "Epoch 880/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3596 - loss: 2.8036 - val_accuracy: 0.0268 - val_loss: 8.9130\n",
      "Epoch 881/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3522 - loss: 2.8329 - val_accuracy: 0.0268 - val_loss: 8.9745\n",
      "Epoch 882/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3375 - loss: 2.8145 - val_accuracy: 0.0268 - val_loss: 9.0688\n",
      "Epoch 883/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3404 - loss: 2.8024 - val_accuracy: 0.0287 - val_loss: 9.0281\n",
      "Epoch 884/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3543 - loss: 2.8161 - val_accuracy: 0.0307 - val_loss: 9.0136\n",
      "Epoch 885/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3523 - loss: 2.7953 - val_accuracy: 0.0287 - val_loss: 8.9979\n",
      "Epoch 886/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3476 - loss: 2.8141 - val_accuracy: 0.0268 - val_loss: 9.0132\n",
      "Epoch 887/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3604 - loss: 2.7719 - val_accuracy: 0.0268 - val_loss: 9.0306\n",
      "Epoch 888/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3516 - loss: 2.8006 - val_accuracy: 0.0249 - val_loss: 9.0234\n",
      "Epoch 889/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3470 - loss: 2.7642 - val_accuracy: 0.0230 - val_loss: 9.0196\n",
      "Epoch 890/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3505 - loss: 2.7818 - val_accuracy: 0.0249 - val_loss: 9.0120\n",
      "Epoch 891/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3692 - loss: 2.7525 - val_accuracy: 0.0268 - val_loss: 8.9882\n",
      "Epoch 892/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3601 - loss: 2.7652 - val_accuracy: 0.0307 - val_loss: 9.0181\n",
      "Epoch 893/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3661 - loss: 2.7717 - val_accuracy: 0.0268 - val_loss: 9.0403\n",
      "Epoch 894/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3687 - loss: 2.7854 - val_accuracy: 0.0230 - val_loss: 9.0572\n",
      "Epoch 895/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3611 - loss: 2.8001 - val_accuracy: 0.0192 - val_loss: 9.0846\n",
      "Epoch 896/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3739 - loss: 2.7697 - val_accuracy: 0.0211 - val_loss: 9.0895\n",
      "Epoch 897/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3911 - loss: 2.7640 - val_accuracy: 0.0249 - val_loss: 9.0607\n",
      "Epoch 898/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3642 - loss: 2.7532 - val_accuracy: 0.0230 - val_loss: 9.0669\n",
      "Epoch 899/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3482 - loss: 2.7726 - val_accuracy: 0.0230 - val_loss: 9.0595\n",
      "Epoch 900/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3362 - loss: 2.7681 - val_accuracy: 0.0268 - val_loss: 9.0408\n",
      "Epoch 901/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3429 - loss: 2.7635 - val_accuracy: 0.0249 - val_loss: 9.0529\n",
      "Epoch 902/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3399 - loss: 2.7639 - val_accuracy: 0.0249 - val_loss: 9.0296\n",
      "Epoch 903/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3527 - loss: 2.7454 - val_accuracy: 0.0287 - val_loss: 9.0575\n",
      "Epoch 904/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3901 - loss: 2.7743 - val_accuracy: 0.0230 - val_loss: 9.0580\n",
      "Epoch 905/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3592 - loss: 2.7224 - val_accuracy: 0.0192 - val_loss: 9.0538\n",
      "Epoch 906/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3685 - loss: 2.7423 - val_accuracy: 0.0211 - val_loss: 9.0545\n",
      "Epoch 907/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.4055 - loss: 2.7449 - val_accuracy: 0.0172 - val_loss: 9.0466\n",
      "Epoch 908/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3882 - loss: 2.7286 - val_accuracy: 0.0192 - val_loss: 9.0478\n",
      "Epoch 909/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3604 - loss: 2.7351 - val_accuracy: 0.0230 - val_loss: 9.0581\n",
      "Epoch 910/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3880 - loss: 2.7307 - val_accuracy: 0.0230 - val_loss: 9.0361\n",
      "Epoch 911/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3890 - loss: 2.7255 - val_accuracy: 0.0249 - val_loss: 9.0462\n",
      "Epoch 912/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3783 - loss: 2.7459 - val_accuracy: 0.0230 - val_loss: 9.0799\n",
      "Epoch 913/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.4001 - loss: 2.7676 - val_accuracy: 0.0268 - val_loss: 9.0747\n",
      "Epoch 914/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3510 - loss: 2.7493 - val_accuracy: 0.0249 - val_loss: 9.0419\n",
      "Epoch 915/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3094 - loss: 2.7708 - val_accuracy: 0.0249 - val_loss: 9.0903\n",
      "Epoch 916/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3960 - loss: 2.7109 - val_accuracy: 0.0249 - val_loss: 9.0804\n",
      "Epoch 917/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3780 - loss: 2.7601 - val_accuracy: 0.0249 - val_loss: 9.0640\n",
      "Epoch 918/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.3303 - loss: 2.7859 - val_accuracy: 0.0249 - val_loss: 9.0558\n",
      "Epoch 919/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3036 - loss: 2.7306 - val_accuracy: 0.0249 - val_loss: 9.1297\n",
      "Epoch 920/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3744 - loss: 2.7493 - val_accuracy: 0.0211 - val_loss: 9.1429\n",
      "Epoch 921/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3465 - loss: 2.8043 - val_accuracy: 0.0268 - val_loss: 9.0200\n",
      "Epoch 922/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2603 - loss: 2.7802 - val_accuracy: 0.0268 - val_loss: 8.9697\n",
      "Epoch 923/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.2606 - loss: 2.7928 - val_accuracy: 0.0230 - val_loss: 8.9867\n",
      "Epoch 924/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2808 - loss: 2.7463 - val_accuracy: 0.0230 - val_loss: 9.1124\n",
      "Epoch 925/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3409 - loss: 2.8169 - val_accuracy: 0.0249 - val_loss: 9.0698\n",
      "Epoch 926/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3255 - loss: 2.7846 - val_accuracy: 0.0287 - val_loss: 8.9883\n",
      "Epoch 927/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3226 - loss: 2.7967 - val_accuracy: 0.0249 - val_loss: 8.9235\n",
      "Epoch 928/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3495 - loss: 2.7494 - val_accuracy: 0.0249 - val_loss: 8.8456\n",
      "Epoch 929/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.3682 - loss: 2.7940 - val_accuracy: 0.0249 - val_loss: 8.9149\n",
      "Epoch 930/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3332 - loss: 2.7656 - val_accuracy: 0.0211 - val_loss: 9.2465\n",
      "Epoch 931/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3466 - loss: 2.8062 - val_accuracy: 0.0211 - val_loss: 9.3045\n",
      "Epoch 932/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3531 - loss: 2.8122 - val_accuracy: 0.0192 - val_loss: 9.2938\n",
      "Epoch 933/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.3419 - loss: 2.7018 - val_accuracy: 0.0192 - val_loss: 9.2652\n",
      "Epoch 934/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3231 - loss: 2.7771 - val_accuracy: 0.0211 - val_loss: 9.2612\n",
      "Epoch 935/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.4045 - loss: 2.7632 - val_accuracy: 0.0211 - val_loss: 9.1396\n",
      "Epoch 936/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3952 - loss: 2.7767 - val_accuracy: 0.0172 - val_loss: 9.0377\n",
      "Epoch 937/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3153 - loss: 2.7847 - val_accuracy: 0.0115 - val_loss: 9.1474\n",
      "Epoch 938/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.3428 - loss: 2.7766 - val_accuracy: 0.0115 - val_loss: 9.1909\n",
      "Epoch 939/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3282 - loss: 2.8091 - val_accuracy: 0.0115 - val_loss: 9.2457\n",
      "Epoch 940/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3361 - loss: 2.7715 - val_accuracy: 0.0192 - val_loss: 9.2265\n",
      "Epoch 941/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2680 - loss: 2.7947 - val_accuracy: 0.0192 - val_loss: 9.2379\n",
      "Epoch 942/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3448 - loss: 2.7842 - val_accuracy: 0.0230 - val_loss: 9.2801\n",
      "Epoch 943/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3743 - loss: 2.7959 - val_accuracy: 0.0230 - val_loss: 9.2841\n",
      "Epoch 944/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3589 - loss: 2.7433 - val_accuracy: 0.0230 - val_loss: 9.2642\n",
      "Epoch 945/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3267 - loss: 2.7535 - val_accuracy: 0.0230 - val_loss: 9.2298\n",
      "Epoch 946/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3240 - loss: 2.7657 - val_accuracy: 0.0230 - val_loss: 9.2212\n",
      "Epoch 947/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3294 - loss: 2.7519 - val_accuracy: 0.0230 - val_loss: 9.1982\n",
      "Epoch 948/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.2774 - loss: 2.8006 - val_accuracy: 0.0211 - val_loss: 9.1623\n",
      "Epoch 949/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2976 - loss: 2.7857 - val_accuracy: 0.0230 - val_loss: 9.1760\n",
      "Epoch 950/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3312 - loss: 2.7617 - val_accuracy: 0.0211 - val_loss: 9.1940\n",
      "Epoch 951/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3449 - loss: 2.7575 - val_accuracy: 0.0211 - val_loss: 9.2053\n",
      "Epoch 952/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3422 - loss: 2.6933 - val_accuracy: 0.0192 - val_loss: 9.2159\n",
      "Epoch 953/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.3537 - loss: 2.6917 - val_accuracy: 0.0230 - val_loss: 9.2356\n",
      "Epoch 954/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3216 - loss: 2.7224 - val_accuracy: 0.0211 - val_loss: 9.2581\n",
      "Epoch 955/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3287 - loss: 2.7164 - val_accuracy: 0.0192 - val_loss: 9.3174\n",
      "Epoch 956/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3411 - loss: 2.7430 - val_accuracy: 0.0230 - val_loss: 9.3182\n",
      "Epoch 957/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3320 - loss: 2.7135 - val_accuracy: 0.0192 - val_loss: 9.3161\n",
      "Epoch 958/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3375 - loss: 2.7047 - val_accuracy: 0.0192 - val_loss: 9.3002\n",
      "Epoch 959/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.3627 - loss: 2.6542 - val_accuracy: 0.0211 - val_loss: 9.2290\n",
      "Epoch 960/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3262 - loss: 2.6779 - val_accuracy: 0.0192 - val_loss: 9.2286\n",
      "Epoch 961/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3248 - loss: 2.6608 - val_accuracy: 0.0192 - val_loss: 9.2368\n",
      "Epoch 962/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3376 - loss: 2.6648 - val_accuracy: 0.0211 - val_loss: 9.2264\n",
      "Epoch 963/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3540 - loss: 2.6867 - val_accuracy: 0.0230 - val_loss: 9.2574\n",
      "Epoch 964/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3721 - loss: 2.6648 - val_accuracy: 0.0192 - val_loss: 9.2284\n",
      "Epoch 965/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3731 - loss: 2.6929 - val_accuracy: 0.0192 - val_loss: 9.1864\n",
      "Epoch 966/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3619 - loss: 2.6930 - val_accuracy: 0.0230 - val_loss: 9.2076\n",
      "Epoch 967/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3274 - loss: 2.6822 - val_accuracy: 0.0211 - val_loss: 9.2827\n",
      "Epoch 968/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3303 - loss: 2.6812 - val_accuracy: 0.0249 - val_loss: 9.3064\n",
      "Epoch 969/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3435 - loss: 2.6622 - val_accuracy: 0.0230 - val_loss: 9.3189\n",
      "Epoch 970/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3505 - loss: 2.6955 - val_accuracy: 0.0211 - val_loss: 9.3309\n",
      "Epoch 971/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2951 - loss: 2.6861 - val_accuracy: 0.0230 - val_loss: 9.3201\n",
      "Epoch 972/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3779 - loss: 2.6820 - val_accuracy: 0.0211 - val_loss: 9.2278\n",
      "Epoch 973/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.4335 - loss: 2.6448 - val_accuracy: 0.0211 - val_loss: 9.2154\n",
      "Epoch 974/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 0.3999 - loss: 2.6858 - val_accuracy: 0.0211 - val_loss: 9.2539\n",
      "Epoch 975/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3567 - loss: 2.6746 - val_accuracy: 0.0230 - val_loss: 9.2697\n",
      "Epoch 976/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.2987 - loss: 2.6212 - val_accuracy: 0.0249 - val_loss: 9.2910\n",
      "Epoch 977/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3321 - loss: 2.6646 - val_accuracy: 0.0211 - val_loss: 9.3223\n",
      "Epoch 978/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3548 - loss: 2.6564 - val_accuracy: 0.0211 - val_loss: 9.3608\n",
      "Epoch 979/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3531 - loss: 2.6098 - val_accuracy: 0.0230 - val_loss: 9.3795\n",
      "Epoch 980/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3880 - loss: 2.5968 - val_accuracy: 0.0211 - val_loss: 9.3903\n",
      "Epoch 981/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3769 - loss: 2.6786 - val_accuracy: 0.0211 - val_loss: 9.3880\n",
      "Epoch 982/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.4092 - loss: 2.5932 - val_accuracy: 0.0230 - val_loss: 9.3891\n",
      "Epoch 983/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3954 - loss: 2.6181 - val_accuracy: 0.0249 - val_loss: 9.3904\n",
      "Epoch 984/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3908 - loss: 2.6222 - val_accuracy: 0.0192 - val_loss: 9.3984\n",
      "Epoch 985/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3423 - loss: 2.6323 - val_accuracy: 0.0211 - val_loss: 9.4046\n",
      "Epoch 986/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3851 - loss: 2.6083 - val_accuracy: 0.0211 - val_loss: 9.4177\n",
      "Epoch 987/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3790 - loss: 2.6092 - val_accuracy: 0.0211 - val_loss: 9.4279\n",
      "Epoch 988/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3727 - loss: 2.6380 - val_accuracy: 0.0192 - val_loss: 9.4577\n",
      "Epoch 989/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3860 - loss: 2.6369 - val_accuracy: 0.0192 - val_loss: 9.4575\n",
      "Epoch 990/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.4088 - loss: 2.6291 - val_accuracy: 0.0211 - val_loss: 9.4760\n",
      "Epoch 991/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.4074 - loss: 2.5702 - val_accuracy: 0.0211 - val_loss: 9.4632\n",
      "Epoch 992/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3879 - loss: 2.5966 - val_accuracy: 0.0192 - val_loss: 9.4666\n",
      "Epoch 993/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3768 - loss: 2.6419 - val_accuracy: 0.0192 - val_loss: 9.4205\n",
      "Epoch 994/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3920 - loss: 2.5821 - val_accuracy: 0.0211 - val_loss: 9.4748\n",
      "Epoch 995/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3972 - loss: 2.6156 - val_accuracy: 0.0230 - val_loss: 9.4854\n",
      "Epoch 996/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3637 - loss: 2.6042 - val_accuracy: 0.0211 - val_loss: 9.4956\n",
      "Epoch 997/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.3899 - loss: 2.5532 - val_accuracy: 0.0192 - val_loss: 9.5039\n",
      "Epoch 998/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4s/step - accuracy: 0.3997 - loss: 2.4966 - val_accuracy: 0.0192 - val_loss: 9.4923\n",
      "Epoch 999/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4s/step - accuracy: 0.3857 - loss: 2.5292 - val_accuracy: 0.0249 - val_loss: 9.3822\n",
      "Epoch 1000/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - accuracy: 0.3787 - loss: 2.6203 - val_accuracy: 0.0211 - val_loss: 9.5036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e91e44d850>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([cobol_sequences, decoder_input_data], decoder_target_data_one_hot, epochs=1000, batch_size=20, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ff9f164b-f408-4489-9132-84ca252bbe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: \"'\",\n",
       " 2: 'print',\n",
       " 3: 'input',\n",
       " 4: 'name',\n",
       " 5: '0',\n",
       " 6: 'num',\n",
       " 7: 'int',\n",
       " 8: 'if',\n",
       " 9: '1',\n",
       " 10: \"'enter\",\n",
       " 11: 'total',\n",
       " 12: 'number',\n",
       " 13: 'main',\n",
       " 14: 'is',\n",
       " 15: 'else',\n",
       " 16: 'idx',\n",
       " 17: 'num1',\n",
       " 18: 'code',\n",
       " 19: 'a',\n",
       " 20: 'ws',\n",
       " 21: 'f',\n",
       " 22: 'num2',\n",
       " 23: 'def',\n",
       " 24: 'max',\n",
       " 25: 'amount',\n",
       " 26: 'i',\n",
       " 27: 'the',\n",
       " 28: 'in',\n",
       " 29: 'para',\n",
       " 30: 'avg',\n",
       " 31: 'rem',\n",
       " 32: 'list',\n",
       " 33: 'sum',\n",
       " 34: 'import',\n",
       " 35: 'format',\n",
       " 36: 'temp',\n",
       " 37: 'inp',\n",
       " 38: '2',\n",
       " 39: 'quo',\n",
       " 40: 'time',\n",
       " 41: 'for',\n",
       " 42: 'enter',\n",
       " 43: 'age',\n",
       " 44: '100',\n",
       " 45: 'and',\n",
       " 46: 'date',\n",
       " 47: 'range',\n",
       " 48: 'option',\n",
       " 49: 'telephone',\n",
       " 50: 'w',\n",
       " 51: '00',\n",
       " 52: 'abend',\n",
       " 53: 'mark1',\n",
       " 54: 'mark2',\n",
       " 55: 'mark3',\n",
       " 56: '5',\n",
       " 57: 'grade',\n",
       " 58: 'given',\n",
       " 59: 'start',\n",
       " 60: 'accept',\n",
       " 61: 'character',\n",
       " 62: 'val',\n",
       " 63: 'of',\n",
       " 64: 'result',\n",
       " 65: 'reason',\n",
       " 66: 'str',\n",
       " 67: 'm',\n",
       " 68: \"'total\",\n",
       " 69: '60',\n",
       " 70: '3',\n",
       " 71: 'end',\n",
       " 72: 'first',\n",
       " 73: 'last',\n",
       " 74: 'indi',\n",
       " 75: 'even',\n",
       " 76: 'odd',\n",
       " 77: '10',\n",
       " 78: 'cleanup',\n",
       " 79: 'datetime',\n",
       " 80: 'obj',\n",
       " 81: 'formatted',\n",
       " 82: 'r',\n",
       " 83: 'inc',\n",
       " 84: 'divmod',\n",
       " 85: 'math',\n",
       " 86: 'sys',\n",
       " 87: 'disp',\n",
       " 88: 'rec',\n",
       " 89: 'char',\n",
       " 90: 'global',\n",
       " 91: 'comp',\n",
       " 92: 'nresult',\n",
       " 93: 'y',\n",
       " 94: 'h',\n",
       " 95: 'empid',\n",
       " 96: 'float',\n",
       " 97: '99',\n",
       " 98: 'b',\n",
       " 99: 'tot',\n",
       " 100: 'fahrenheit',\n",
       " 101: '9',\n",
       " 102: 'p',\n",
       " 103: '80',\n",
       " 104: '40',\n",
       " 105: 'per',\n",
       " 106: 'res',\n",
       " 107: 'stop',\n",
       " 108: 'increment',\n",
       " 109: 'isdcode',\n",
       " 110: 'stdcode',\n",
       " 111: 'areacode',\n",
       " 112: '6',\n",
       " 113: 'full',\n",
       " 114: 'pay',\n",
       " 115: 'returns',\n",
       " 116: 'nnum2',\n",
       " 117: 'nprint',\n",
       " 118: 'cee3ab2',\n",
       " 119: 'rollno',\n",
       " 120: 'stuname',\n",
       " 121: 'no',\n",
       " 122: 'marks',\n",
       " 123: 'strptime',\n",
       " 124: \"d'\",\n",
       " 125: \"s'\",\n",
       " 126: 'strftime',\n",
       " 127: 'empid2',\n",
       " 128: 'alpnum',\n",
       " 129: \"'temp\",\n",
       " 130: 'zz99',\n",
       " 131: '999',\n",
       " 132: '45',\n",
       " 133: 'celcius',\n",
       " 134: 't',\n",
       " 135: 'ii',\n",
       " 136: 'iii',\n",
       " 137: 'fail',\n",
       " 138: 'average',\n",
       " 139: 'percentage',\n",
       " 140: 'while',\n",
       " 141: 'prime',\n",
       " 142: 'at',\n",
       " 143: 'days',\n",
       " 144: 'd',\n",
       " 145: '18',\n",
       " 146: '30',\n",
       " 147: 'upper',\n",
       " 148: '51',\n",
       " 149: \"'hello\",\n",
       " 150: 'world',\n",
       " 151: '200',\n",
       " 152: \"f'sum\",\n",
       " 153: '20',\n",
       " 154: \"f'product\",\n",
       " 155: \"'ceeab2\",\n",
       " 156: \"'cleanup\",\n",
       " 157: '123',\n",
       " 158: '456',\n",
       " 159: '789',\n",
       " 160: \"'num1\",\n",
       " 161: \"'num2\",\n",
       " 162: 'roll',\n",
       " 163: 'split',\n",
       " 164: \"f'roll\",\n",
       " 165: 'from',\n",
       " 166: 'yymmdd',\n",
       " 167: 'hhmmss',\n",
       " 168: \"'date\",\n",
       " 169: \"'time\",\n",
       " 170: '3454',\n",
       " 171: \"'abc123'\",\n",
       " 172: \"'empid\",\n",
       " 173: \"'empid2\",\n",
       " 174: \"'alpnum\",\n",
       " 175: 'with',\n",
       " 176: 'two',\n",
       " 177: 'decimal',\n",
       " 178: 'places',\n",
       " 179: 'num3',\n",
       " 180: 'num4',\n",
       " 181: 'num5',\n",
       " 182: 'num6',\n",
       " 183: 'num7',\n",
       " 184: '99cr',\n",
       " 185: '23',\n",
       " 186: '678',\n",
       " 187: '29',\n",
       " 188: '459',\n",
       " 189: \"'ws\",\n",
       " 190: 'temperature',\n",
       " 191: 'celsius',\n",
       " 192: '32',\n",
       " 193: \"'temperature\",\n",
       " 194: 'principal',\n",
       " 195: 'rate',\n",
       " 196: 'interest',\n",
       " 197: 'period',\n",
       " 198: \"'interest\",\n",
       " 199: '300',\n",
       " 200: '79',\n",
       " 201: 'break',\n",
       " 202: 'non',\n",
       " 203: 'value',\n",
       " 204: 'digits',\n",
       " 205: 'nend',\n",
       " 206: 'nincrement',\n",
       " 207: 'nrem',\n",
       " 208: 'nquo',\n",
       " 209: 'was',\n",
       " 210: 'nan',\n",
       " 211: 're',\n",
       " 212: 'isd',\n",
       " 213: 'std',\n",
       " 214: 'area',\n",
       " 215: 'exit',\n",
       " 216: 'd1',\n",
       " 217: 'sunday',\n",
       " 218: 'd2',\n",
       " 219: 'monday',\n",
       " 220: 'd3',\n",
       " 221: 'tuesday',\n",
       " 222: 'd4',\n",
       " 223: 'wednesday',\n",
       " 224: 'd5',\n",
       " 225: 'thursday',\n",
       " 226: 'd6',\n",
       " 227: 'friday',\n",
       " 228: 'd7',\n",
       " 229: 'saturday',\n",
       " 230: '8',\n",
       " 231: 'fixed',\n",
       " 232: 'basic',\n",
       " 233: 'da',\n",
       " 234: 'additional',\n",
       " 235: 'hra',\n",
       " 236: 'monthly',\n",
       " 237: 'incentive',\n",
       " 238: 'deductions',\n",
       " 239: 'pf',\n",
       " 240: 'it',\n",
       " 241: 'other',\n",
       " 242: 'lambda',\n",
       " 243: '07',\n",
       " 244: '09',\n",
       " 245: '11',\n",
       " 246: '41',\n",
       " 247: '12',\n",
       " 248: 'vowel',\n",
       " 249: 'e',\n",
       " 250: 'o',\n",
       " 251: 'u',\n",
       " 252: 'consonent',\n",
       " 253: 'c',\n",
       " 254: 'g',\n",
       " 255: 'j',\n",
       " 256: 'k',\n",
       " 257: 'l',\n",
       " 258: 'n',\n",
       " 259: 'q',\n",
       " 260: 's',\n",
       " 261: 'v',\n",
       " 262: 'x',\n",
       " 263: 'z',\n",
       " 264: 'digit',\n",
       " 265: 'isdigit',\n",
       " 266: 'an',\n",
       " 267: 'invalid',\n",
       " 268: '50',\n",
       " 269: 'setitem',\n",
       " 270: '101'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6adef7d1-1963-45df-8d98-8e55679c1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture, weights, and training configuration\n",
    "model.save(\"cobol_to_python_translator.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "67261201-ac77-465e-8316-3f8f2d42a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to translate COBOL code to Python\n",
    "def translate_cobol_to_python(cobol_code):\n",
    "  # Preprocess the COBOL code\n",
    "  cobol_sequence = cobol_tokenizer.texts_to_sequences([cobol_code])[0]\n",
    "  cobol_sequence = pad_sequences([cobol_sequence], maxlen=max_cobol_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e16657a6-d596-4f02-9579-242917915b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 41\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Define the end-of-sequence token (replace with the actual token index)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     40\u001b[0m cobol_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIDENTIFICATION DIVISION. PROGRAM-ID. HelloWorld. PROCEDURE DIVISION. DISPLAY \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello, World!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. STOP RUN..\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 41\u001b[0m translated_python_code \u001b[38;5;241m=\u001b[39m translate_cobol_to_python(cobol_code)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(translated_python_code)\n",
      "Cell \u001b[1;32mIn[122], line 34\u001b[0m, in \u001b[0;36mtranslate_cobol_to_python\u001b[1;34m(cobol_code)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;66;03m# Handle empty sequence (e.g., print a message)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not predict any Python code.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(translated_python_code)\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the saved model\n",
    "translator_model = load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/cobol_to_python_translator.keras\")\n",
    "\n",
    "# Define a function to translate COBOL code to Python\n",
    "def translate_cobol_to_python(cobol_code):\n",
    "  # Preprocess the COBOL code\n",
    "  cobol_sequence = cobol_tokenizer.texts_to_sequences([cobol_code])[0]\n",
    "  cobol_sequence = pad_sequences([cobol_sequence], maxlen=max_cobol_length, padding=\"post\")\n",
    "\n",
    "  # Predict the Python code sequence\n",
    "  predicted_python_sequence = translator_model.predict([cobol_sequence, np.zeros((1, max_python_length - 1))])[0]\n",
    "  END_TOKEN = 270\n",
    "  # Convert the predicted sequence to Python code\n",
    "  predicted_word = None  # Initialize outside the loop\n",
    "\n",
    "  translated_python_code = []\n",
    "\n",
    "  for i in range(max_python_length):\n",
    "    # ... (rest of your loop logic)\n",
    "    translated_python_code.append(predicted_word)\n",
    "    if predicted_word == END_TOKEN:\n",
    "      break\n",
    "\n",
    "  # Check if translated_python_code has elements before slicing\n",
    "  if translated_python_code:\n",
    "    translated_python_code = translated_python_code[:translated_python_code.index(END_TOKEN) if END_TOKEN in translated_python_code else None]\n",
    "  else:\n",
    "    # Handle empty sequence (e.g., print a message)\n",
    "    print(\"Model did not predict any Python code.\")\n",
    "\n",
    "  return \" \".join(translated_python_code)\n",
    "\n",
    "# Define the end-of-sequence token (replace with the actual token index)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "cobol_code = \"IDENTIFICATION DIVISION. PROGRAM-ID. HelloWorld. PROCEDURE DIVISION. DISPLAY 'Hello, World!'. STOP RUN..\"\n",
    "translated_python_code = translate_cobol_to_python(cobol_code)\n",
    "print(translated_python_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83edbf94-c97a-41cd-bb6c-2b76843f9515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7601dcfb-bfd8-47ac-83be-bd515744fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "###13-05-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1ee0a2-fa48-4ee4-8ffd-10a74612d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Single example of COBOL and Python code snippets\n",
    "cobol_code = \"IDENTIFICATION DIVISION. PROGRAM-ID. HelloWorld. PROCEDURE DIVISION. DISPLAY 'Hello, World!'. STOP RUN.\"\n",
    "python_code = \"print('Hello, World!')\"\n",
    "\n",
    "# Create a dataset (you can expand this to include more examples)\n",
    "data = [(cobol_code, python_code)]\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['cobol_code', 'python_code'])\n",
    "\n",
    "# Tokenization\n",
    "cobol_tokenizer = Tokenizer(filters='', char_level=True)\n",
    "cobol_tokenizer.fit_on_texts(df['cobol_code'])\n",
    "cobol_seq = cobol_tokenizer.texts_to_sequences(df['cobol_code'])\n",
    "cobol_seq_padded = pad_sequences(cobol_seq, padding='post')\n",
    "\n",
    "python_tokenizer = Tokenizer(filters='', char_level=True)\n",
    "python_tokenizer.fit_on_texts(df['python_code'])\n",
    "python_seq = python_tokenizer.texts_to_sequences(df['python_code'])\n",
    "python_seq_padded = pad_sequences(python_seq, padding='post')\n",
    "\n",
    "# Train the model (you'll need to define the model architecture and compile it)\n",
    "# model.fit([cobol_seq_padded, python_seq_padded], np.expand_dims(python_seq_padded, -1), batch_size=64, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7782f7-c673-4f6e-980a-4729c4d4278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'l',\n",
       " 2: 'r',\n",
       " 3: \"'\",\n",
       " 4: 'o',\n",
       " 5: 'p',\n",
       " 6: 'i',\n",
       " 7: 'n',\n",
       " 8: 't',\n",
       " 9: '(',\n",
       " 10: 'h',\n",
       " 11: 'e',\n",
       " 12: ',',\n",
       " 13: ' ',\n",
       " 14: 'w',\n",
       " 15: 'd',\n",
       " 16: '!',\n",
       " 17: ')'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8c8e-3395-4c6e-acf1-6ba5e725e413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
