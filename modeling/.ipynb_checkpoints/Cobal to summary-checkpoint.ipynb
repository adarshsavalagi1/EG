{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0f0adfa-d2b1-4b1b-80bc-fe87e51ede18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/datasets/Cbl_sumry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9a810371-2271-4418-8ff9-f5e6e3bc8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_cobol = Tokenizer(filters='')\n",
    "tokenizer_cobol.fit_on_texts(df['cobol_code'])\n",
    "tokenizer_summary = Tokenizer(filters='')\n",
    "tokenizer_summary.fit_on_texts(df['summary'])\n",
    "\n",
    "# Define the vocabulary sizes\n",
    "vocab_size_cobol = len(tokenizer_cobol.word_index) + 1\n",
    "vocab_size_summary = len(tokenizer_summary.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "384ae868-b97c-495f-960a-9e973f201d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer_cobol.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7fd92beb-61b5-4abc-9d00-9363f941761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer_summary.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2c073084-6973-4342-8104-56f7b8e8a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input-output pairs\n",
    "X = tokenizer_cobol.texts_to_sequences(df['cobol_code'])\n",
    "Y = tokenizer_summary.texts_to_sequences(df['summary'])\n",
    "# Pad sequences\n",
    "max_len_cobol = max([len(seq) for seq in X])\n",
    "max_len_summary = max([len(seq) for seq in Y])\n",
    "\n",
    "X = pad_sequences(X, maxlen=max_len_cobol, padding='post')\n",
    "Y = pad_sequences(Y, maxlen=max_len_summary, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92008beb-2312-4135-a738-91f2683f3b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ea8de850-834c-4091-aca5-ab14f197fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the target sequences for training\n",
    "Y_input = Y[:, :-1]\n",
    "Y_output = Y[:, 1:]\n",
    "\n",
    "# Define the Seq2Seq model\n",
    "latent_dim = 512\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len_cobol,))\n",
    "encoder_embedding = Embedding(vocab_size_cobol, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_len_summary-1,))\n",
    "decoder_embedding = Embedding(vocab_size_summary, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size_summary, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dccaff73-68bb-4407-8941-01d777ec0cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 730ms/step - accuracy: 0.2275 - loss: 5.2145 - val_accuracy: 0.9829 - val_loss: 5.1743\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 494ms/step - accuracy: 0.6804 - loss: 5.1311 - val_accuracy: 0.9701 - val_loss: 5.1184\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 547ms/step - accuracy: 0.5422 - loss: 4.9145 - val_accuracy: 0.3248 - val_loss: 5.0867\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 529ms/step - accuracy: 0.4409 - loss: 4.6921 - val_accuracy: 0.8120 - val_loss: 5.0509\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 509ms/step - accuracy: 0.6764 - loss: 4.4322 - val_accuracy: 0.7692 - val_loss: 5.0441\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 484ms/step - accuracy: 0.6694 - loss: 4.2525 - val_accuracy: 0.9145 - val_loss: 4.9962\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 478ms/step - accuracy: 0.7104 - loss: 4.0407 - val_accuracy: 0.4231 - val_loss: 4.9761\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 522ms/step - accuracy: 0.4870 - loss: 3.7835 - val_accuracy: 0.0000e+00 - val_loss: 4.9673\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 530ms/step - accuracy: 0.1889 - loss: 3.7581 - val_accuracy: 0.2201 - val_loss: 4.9340\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 613ms/step - accuracy: 0.3985 - loss: 3.5331 - val_accuracy: 0.8996 - val_loss: 4.9127\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 467ms/step - accuracy: 0.6637 - loss: 3.5586 - val_accuracy: 0.9145 - val_loss: 4.8768\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 504ms/step - accuracy: 0.6415 - loss: 3.2981 - val_accuracy: 0.1068 - val_loss: 4.8975\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 565ms/step - accuracy: 0.2851 - loss: 3.2616 - val_accuracy: 0.8996 - val_loss: 4.8606\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 500ms/step - accuracy: 0.5060 - loss: 3.3366 - val_accuracy: 0.9017 - val_loss: 4.8538\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 567ms/step - accuracy: 0.6646 - loss: 3.2098 - val_accuracy: 0.8953 - val_loss: 4.8392\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 585ms/step - accuracy: 0.6780 - loss: 2.9444 - val_accuracy: 0.9231 - val_loss: 4.8040\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 587ms/step - accuracy: 0.6387 - loss: 2.7716 - val_accuracy: 0.9124 - val_loss: 4.8083\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 512ms/step - accuracy: 0.7214 - loss: 3.1099 - val_accuracy: 0.2073 - val_loss: 4.7720\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 623ms/step - accuracy: 0.5266 - loss: 2.7839 - val_accuracy: 0.3996 - val_loss: 4.7734\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 722ms/step - accuracy: 0.4006 - loss: 2.5799 - val_accuracy: 0.9295 - val_loss: 4.7361\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 547ms/step - accuracy: 0.5903 - loss: 2.5925 - val_accuracy: 0.4380 - val_loss: 4.7519\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 558ms/step - accuracy: 0.4181 - loss: 2.5703 - val_accuracy: 0.8440 - val_loss: 4.7287\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 595ms/step - accuracy: 0.4906 - loss: 2.3817 - val_accuracy: 0.2799 - val_loss: 4.7056\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 553ms/step - accuracy: 0.4064 - loss: 2.4019 - val_accuracy: 0.4551 - val_loss: 4.7032\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 525ms/step - accuracy: 0.4040 - loss: 2.2177 - val_accuracy: 0.3868 - val_loss: 4.6995\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 509ms/step - accuracy: 0.3925 - loss: 2.1176 - val_accuracy: 0.3889 - val_loss: 4.6776\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 542ms/step - accuracy: 0.4273 - loss: 2.1024 - val_accuracy: 0.4722 - val_loss: 4.6336\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 492ms/step - accuracy: 0.4908 - loss: 2.1235 - val_accuracy: 0.3141 - val_loss: 4.6796\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 488ms/step - accuracy: 0.4385 - loss: 1.8908 - val_accuracy: 0.3996 - val_loss: 4.6372\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 509ms/step - accuracy: 0.4972 - loss: 1.8352 - val_accuracy: 0.8590 - val_loss: 4.6677\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - accuracy: 0.5087 - loss: 1.8366 - val_accuracy: 0.2222 - val_loss: 4.6573\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 602ms/step - accuracy: 0.3732 - loss: 1.6868 - val_accuracy: 0.6368 - val_loss: 4.6167\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 531ms/step - accuracy: 0.4300 - loss: 1.7096 - val_accuracy: 0.7030 - val_loss: 4.5632\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 514ms/step - accuracy: 0.4456 - loss: 1.6341 - val_accuracy: 0.1603 - val_loss: 4.6095\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 637ms/step - accuracy: 0.3874 - loss: 1.5674 - val_accuracy: 0.6752 - val_loss: 4.5844\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 533ms/step - accuracy: 0.5032 - loss: 1.4153 - val_accuracy: 0.8483 - val_loss: 4.5884\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 544ms/step - accuracy: 0.5231 - loss: 1.3798 - val_accuracy: 0.2457 - val_loss: 4.5612\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 611ms/step - accuracy: 0.4018 - loss: 1.5779 - val_accuracy: 0.8611 - val_loss: 4.5390\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 665ms/step - accuracy: 0.5385 - loss: 1.3767 - val_accuracy: 0.8120 - val_loss: 4.5600\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 479ms/step - accuracy: 0.5542 - loss: 1.2426 - val_accuracy: 0.6581 - val_loss: 4.5487\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 529ms/step - accuracy: 0.5457 - loss: 1.2165 - val_accuracy: 0.8718 - val_loss: 4.5392\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 566ms/step - accuracy: 0.6117 - loss: 1.1186 - val_accuracy: 0.8462 - val_loss: 4.5139\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 502ms/step - accuracy: 0.5278 - loss: 1.4127 - val_accuracy: 0.3440 - val_loss: 4.5063\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 490ms/step - accuracy: 0.4926 - loss: 1.3385 - val_accuracy: 0.8632 - val_loss: 4.5046\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 573ms/step - accuracy: 0.6015 - loss: 0.9521 - val_accuracy: 0.8526 - val_loss: 4.5069\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 642ms/step - accuracy: 0.5477 - loss: 1.1160 - val_accuracy: 0.8675 - val_loss: 4.4542\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 604ms/step - accuracy: 0.6264 - loss: 0.9684 - val_accuracy: 0.8632 - val_loss: 4.4753\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 578ms/step - accuracy: 0.5919 - loss: 0.8663 - val_accuracy: 0.8483 - val_loss: 4.4915\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 570ms/step - accuracy: 0.5729 - loss: 0.9225 - val_accuracy: 0.5321 - val_loss: 4.5062\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 600ms/step - accuracy: 0.5335 - loss: 0.9014 - val_accuracy: 0.8953 - val_loss: 4.4389\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 538ms/step - accuracy: 0.7047 - loss: 0.7238 - val_accuracy: 0.9124 - val_loss: 4.4503\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 537ms/step - accuracy: 0.7562 - loss: 0.7015 - val_accuracy: 0.9081 - val_loss: 4.4210\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 535ms/step - accuracy: 0.7248 - loss: 0.7153 - val_accuracy: 0.4295 - val_loss: 4.4320\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 518ms/step - accuracy: 0.5869 - loss: 0.8229 - val_accuracy: 0.8590 - val_loss: 4.4131\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 672ms/step - accuracy: 0.6470 - loss: 0.6211 - val_accuracy: 0.8632 - val_loss: 4.3933\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 499ms/step - accuracy: 0.6066 - loss: 0.7339 - val_accuracy: 0.7115 - val_loss: 4.4122\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 511ms/step - accuracy: 0.6262 - loss: 0.6257 - val_accuracy: 0.8162 - val_loss: 4.3815\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 598ms/step - accuracy: 0.6454 - loss: 0.6081 - val_accuracy: 0.9060 - val_loss: 4.3301\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 530ms/step - accuracy: 0.7420 - loss: 0.5809 - val_accuracy: 0.9038 - val_loss: 4.3447\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 637ms/step - accuracy: 0.8065 - loss: 0.5324 - val_accuracy: 0.8974 - val_loss: 4.3584\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 523ms/step - accuracy: 0.7576 - loss: 0.4874 - val_accuracy: 0.8910 - val_loss: 4.3237\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 571ms/step - accuracy: 0.7821 - loss: 0.7349 - val_accuracy: 0.9017 - val_loss: 4.3156\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 520ms/step - accuracy: 0.7952 - loss: 0.5360 - val_accuracy: 0.8782 - val_loss: 4.3340\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 496ms/step - accuracy: 0.7730 - loss: 0.5034 - val_accuracy: 0.8782 - val_loss: 4.3429\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 553ms/step - accuracy: 0.7518 - loss: 0.4633 - val_accuracy: 0.8739 - val_loss: 4.3348\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 591ms/step - accuracy: 0.7803 - loss: 0.4035 - val_accuracy: 0.8483 - val_loss: 4.3329\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 633ms/step - accuracy: 0.7704 - loss: 0.5288 - val_accuracy: 0.8868 - val_loss: 4.3005\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 582ms/step - accuracy: 0.7553 - loss: 0.4543 - val_accuracy: 0.8419 - val_loss: 4.3125\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 601ms/step - accuracy: 0.8048 - loss: 0.3962 - val_accuracy: 0.8355 - val_loss: 4.3172\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 520ms/step - accuracy: 0.7995 - loss: 0.4276 - val_accuracy: 0.8291 - val_loss: 4.3259\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 521ms/step - accuracy: 0.7197 - loss: 0.3367 - val_accuracy: 0.8462 - val_loss: 4.3000\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 507ms/step - accuracy: 0.8912 - loss: 0.3244 - val_accuracy: 0.7906 - val_loss: 4.3393\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 498ms/step - accuracy: 0.7266 - loss: 0.3991 - val_accuracy: 0.7821 - val_loss: 4.3854\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 554ms/step - accuracy: 0.7518 - loss: 0.3447 - val_accuracy: 0.8355 - val_loss: 4.3181\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 684ms/step - accuracy: 0.8622 - loss: 0.3502 - val_accuracy: 0.8355 - val_loss: 4.3329\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 586ms/step - accuracy: 0.8647 - loss: 0.3034 - val_accuracy: 0.8376 - val_loss: 4.3241\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 586ms/step - accuracy: 0.7648 - loss: 0.3373 - val_accuracy: 0.8397 - val_loss: 4.3141\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 703ms/step - accuracy: 0.8306 - loss: 0.3148 - val_accuracy: 0.8376 - val_loss: 4.3159\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 535ms/step - accuracy: 0.8449 - loss: 0.2847 - val_accuracy: 0.8397 - val_loss: 4.3119\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 500ms/step - accuracy: 0.7900 - loss: 0.2862 - val_accuracy: 0.8034 - val_loss: 4.3459\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 506ms/step - accuracy: 0.7647 - loss: 0.2989 - val_accuracy: 0.8269 - val_loss: 4.3464\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.8375 - loss: 0.2682 - val_accuracy: 0.8462 - val_loss: 4.2956\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 600ms/step - accuracy: 0.8774 - loss: 0.2465 - val_accuracy: 0.7073 - val_loss: 4.3287\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 588ms/step - accuracy: 0.8539 - loss: 0.2550 - val_accuracy: 0.8312 - val_loss: 4.3432\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 582ms/step - accuracy: 0.9272 - loss: 0.2309 - val_accuracy: 0.8462 - val_loss: 4.3054\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 605ms/step - accuracy: 0.9165 - loss: 0.2319 - val_accuracy: 0.8312 - val_loss: 4.3297\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 529ms/step - accuracy: 0.9175 - loss: 0.1924 - val_accuracy: 0.8355 - val_loss: 4.3038\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 508ms/step - accuracy: 0.9211 - loss: 0.3813 - val_accuracy: 0.8355 - val_loss: 4.3260\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 498ms/step - accuracy: 0.8282 - loss: 0.2983 - val_accuracy: 0.8269 - val_loss: 4.3285\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 503ms/step - accuracy: 0.8726 - loss: 0.2133 - val_accuracy: 0.8333 - val_loss: 4.3330\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 491ms/step - accuracy: 0.9007 - loss: 0.1849 - val_accuracy: 0.8376 - val_loss: 4.3008\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 486ms/step - accuracy: 0.9280 - loss: 0.1762 - val_accuracy: 0.8376 - val_loss: 4.2966\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 495ms/step - accuracy: 0.9433 - loss: 0.1707 - val_accuracy: 0.8291 - val_loss: 4.3022\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 495ms/step - accuracy: 0.9118 - loss: 0.1844 - val_accuracy: 0.8269 - val_loss: 4.3573\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 495ms/step - accuracy: 0.8872 - loss: 0.1645 - val_accuracy: 0.8397 - val_loss: 4.3011\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 487ms/step - accuracy: 0.9347 - loss: 0.1773 - val_accuracy: 0.8333 - val_loss: 4.3586\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 492ms/step - accuracy: 0.8215 - loss: 0.1991 - val_accuracy: 0.8376 - val_loss: 4.3196\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 498ms/step - accuracy: 0.9437 - loss: 0.1796 - val_accuracy: 0.8376 - val_loss: 4.3148\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 486ms/step - accuracy: 0.9260 - loss: 0.1509 - val_accuracy: 0.8355 - val_loss: 4.3232\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 492ms/step - accuracy: 0.9594 - loss: 0.1608 - val_accuracy: 0.8355 - val_loss: 4.3168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x221c5a7f450>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([X, Y[:,:-1]], Y.reshape(Y.shape[0], Y.shape[1], 1)[:,1:],batch_size=10, epochs=100, validation_split=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8ee7f066-6061-42c5-a641-24e4acd5e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('seq2seq_model_.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c711bf44-421b-48b3-b478-638adb28ff87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_9\" is incompatible with the layer: expected shape=(None, 32), found shape=(9, 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([X_test, Y_test[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Convert predictions to sequences of token ids\u001b[39;00m\n\u001b[0;32m     34\u001b[0m Y_pred_sequences \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_9\" is incompatible with the layer: expected shape=(None, 32), found shape=(9, 19)"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming your test data is loaded and preprocessed similarly to the training data\n",
    "df_test = pd.read_csv(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/Dataset/test.csv\")\n",
    "X_test = tokenizer_cobol.texts_to_sequences(df_test['cobol_code'])\n",
    "Y_test = tokenizer_summary.texts_to_sequences(df_test['summary'])\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len_cobol, padding='post')\n",
    "Y_test = pad_sequences(Y_test, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/seq2seq_model_.keras\")\n",
    "\n",
    "# Function to calculate sequence accuracy\n",
    "def sequence_accuracy(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for true_seq, pred_seq in zip(y_true, y_pred):\n",
    "        true_seq = true_seq[true_seq != 0]  # Remove padding\n",
    "        pred_seq = pred_seq[:len(true_seq)]  # Truncate to the length of the true sequence\n",
    "        if np.array_equal(true_seq, pred_seq):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n",
    "# Generate predictions\n",
    "Y_pred = model.predict([X_test, Y_test[:, :-1]])\n",
    "\n",
    "# Convert predictions to sequences of token ids\n",
    "Y_pred_sequences = np.argmax(Y_pred, axis=-1)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = sequence_accuracy(Y_test[:, 1:], Y_pred_sequences)\n",
    "print(f'Sequence Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f8257ae5-0cfb-4c88-a30d-f5cca7be0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/Jabasingh Daniel/Desktop/EGDK/modeling/seq2seq_model.keras\")\n",
    "\n",
    "def preprocess_input(cobol_code, tokenizer_cobol, max_len_cobol):\n",
    "    # Tokenize the input COBOL code\n",
    "    sequence = tokenizer_cobol.texts_to_sequences([cobol_code])\n",
    "    # Pad the sequence\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len_cobol, padding='post')\n",
    "    return padded_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "79da8e92-57c8-44e1-b84d-327d6b895118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_summary(cobol_code, model, tokenizer_cobol, tokenizer_summary, max_len_cobol, max_len_summary):\n",
    "    # Preprocess the input COBOL code\n",
    "    input_seq = preprocess_input(cobol_code, tokenizer_cobol, max_len_cobol)\n",
    "    \n",
    "    # Initialize the decoder input\n",
    "    decoder_input = np.zeros((1, max_len_summary - 1))\n",
    "    \n",
    "    # Predict the summary\n",
    "    for i in range(max_len_summary - 1):\n",
    "        output_tokens = model.predict([input_seq, decoder_input])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, i, :])\n",
    "        decoder_input[0, i] = sampled_token_index\n",
    "        \n",
    "        # Stop if a zero token (padding) is predicted, indicating no more meaningful tokens\n",
    "        if sampled_token_index == 0:\n",
    "            break\n",
    "    \n",
    "    # Convert token indices back to words\n",
    "    predicted_summary = []\n",
    "    for token in decoder_input[0]:\n",
    "        if token == 0:\n",
    "            continue\n",
    "        word = tokenizer_summary.index_word.get(token, '')\n",
    "        predicted_summary.append(word)\n",
    "    \n",
    "    return ' '.join(predicted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee1495e2-d8ad-4bd7-be39-113019666b96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_9\" is incompatible with the layer: expected shape=(None, 32), found shape=(1, 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m cobol_code_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSORT \u001b[39m\u001b[38;5;132;01m{DATASET}\u001b[39;00m\u001b[38;5;124m ON ASCENDING KEY \u001b[39m\u001b[38;5;132;01m{KEY1}\u001b[39;00m\u001b[38;5;124m USING \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mINPUT-FILE} GIVING \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mOUTPUT-FILE}.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict the summary\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m summary \u001b[38;5;241m=\u001b[39m predict_summary(cobol_code_example, model, tokenizer_cobol, tokenizer_summary, max_len_cobol, max_len_summary)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[115], line 10\u001b[0m, in \u001b[0;36mpredict_summary\u001b[1;34m(cobol_code, model, tokenizer_cobol, tokenizer_summary, max_len_cobol, max_len_summary)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Predict the summary\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len_summary \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([input_seq, decoder_input])\n\u001b[0;32m     11\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, i, :])\n\u001b[0;32m     12\u001b[0m     decoder_input[\u001b[38;5;241m0\u001b[39m, i] \u001b[38;5;241m=\u001b[39m sampled_token_index\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_9\" is incompatible with the layer: expected shape=(None, 32), found shape=(1, 19)"
     ]
    }
   ],
   "source": [
    "# Define your COBOL code to be summarized\n",
    "cobol_code_example = \"SORT {DATASET} ON ASCENDING KEY {KEY1} USING {INPUT-FILE} GIVING {OUTPUT-FILE}.\"\n",
    "\n",
    "# Predict the summary\n",
    "summary = predict_summary(cobol_code_example, model, tokenizer_cobol, tokenizer_summary, max_len_cobol, max_len_summary)\n",
    "print(f'Summary: {summary}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a3cd9-1b24-46fd-ba9f-13bcbc42bde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aae4bd-5c2c-4805-9e6a-a25966fd4f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
